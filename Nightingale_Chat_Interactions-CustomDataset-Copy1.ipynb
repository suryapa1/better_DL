{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas import DataFrame\n",
    "from pandas.io.json import json_normalize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low       567\n",
      "high      446\n",
      "medium    426\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/home/surya/Nightingale_Chat.xlsx\",sheet_name = \"All\", header=0)\n",
    "print(df.rating.value_counts())\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"/home/surya/NG_Chatdata.xlsx\",sheet_name = \"all\", header=0)\n",
    "# print(df.rating.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        patient_chat  rating  \\\n",
      "0  female, 55 years, 75 kg and obese. hypertensiv...     NaN   \n",
      "1  I'm 22 and male and I have gotten terrible mig...     NaN   \n",
      "2  My wife is constantly suffering from high bloo...     NaN   \n",
      "3  I get head aches multiple time times a week I'...     NaN   \n",
      "4  I recently suffered a substantial loss of belo...     NaN   \n",
      "\n",
      "                                       clean_doc_voc  \n",
      "0  female 55 years 75 kg obese hypertensive 16011...  \n",
      "1  im 22 male gotten terrible migraines regular b...  \n",
      "2  wife constantly suffering high blood pressure ...  \n",
      "3  get head aches multiple time times week ive ro...  \n",
      "4  recently suffered substantial loss beloved obj...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    with open(filename) as f:\n",
    "        d = json.load(f)\n",
    "        df = DataFrame(d)\n",
    "        f.close()\n",
    "    return df\n",
    "\n",
    "punc_ = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(doc) :\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = doc.lower().split()\n",
    "#     tokens = [w for w in tokens if '@' not in w]\n",
    "    \n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha() or word.isalnum()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [word for word in tokens if word not in punc_]\n",
    "    tokens = [re.sub('[^A-Za-z0-9]+', '', word)  for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "def preprocess_documents(docs):\n",
    "    clean_docs = [clean_document(doc) for doc in docs]\n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df.patient_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_docs = preprocess_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vocobulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(doc,vocab):\n",
    "    vocab.update(doc)\n",
    "    return vocab\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(clean_docs, vocab):\n",
    "    for doc in clean_docs:\n",
    "        vocab = add_doc_to_vocab(doc, vocab)\n",
    "    return vocab\n",
    "\n",
    "vocab = process_docs(clean_docs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947\n"
     ]
    }
   ],
   "source": [
    "# keep tokens with a min occurrence\n",
    "min_occurrence = 2\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurrence]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "    # convert lines to a single blob of text\n",
    "    data = '\\n'.join(lines)\n",
    "    # open file\n",
    "    file = open(filename, 'w')\n",
    "    # write text\n",
    "    file.write(data)\n",
    "    # close file\n",
    "    file.close()\n",
    "    \n",
    "# save tokens to a vocabulary file\n",
    "save_list(tokens, 'nightingale_vocab.txt')\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(doc, vocab):\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in doc if w in vocab]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vocabulary\n",
    "vocab_filename = 'nightingale_vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = set(vocab.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female 55 years 75 kg obese hypertensive 160110 hg doctor prescribes olmesartan suffering severe headache'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_line(clean_docs[0], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_doc_voc = []\n",
    "for doc in clean_docs:\n",
    "    clean_doc_voc.append(doc_to_line(doc, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_doc_voc\"] = clean_doc_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_chat', 'rating', 'clean_doc_voc'], dtype='object')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating  = df.rating.map({'low':0, 'medium':1, 'high' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X.index,y,test_size=0.2)\n",
    "train, test = train_test_split(df[[\"clean_doc_voc\",\"rating\" ]], test_size=0.2)\n",
    "\n",
    "xtrain_docs , y_train_docs= train[\"clean_doc_voc\"] , train[\"rating\"]\n",
    "xtest_docs , y_test_docs= test[\"clean_doc_voc\"] , test[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data\n",
    "tokenizer = create_tokenizer(xtrain_docs)\n",
    "Xtrain = tokenizer.texts_to_matrix(xtrain_docs, mode='freq' )\n",
    "Xtest = tokenizer.texts_to_matrix(xtest_docs, mode='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1151, 2892), (1151,))\n",
      "((288,), (288,))\n"
     ]
    }
   ],
   "source": [
    "print((Xtrain.shape ,y_train_docs.shape))\n",
    "print((xtest_docs.shape, y_test_docs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671    NaN\n",
       "444    NaN\n",
       "1212   NaN\n",
       "1144   NaN\n",
       "332    NaN\n",
       "1196   NaN\n",
       "570    NaN\n",
       "1338   NaN\n",
       "392    NaN\n",
       "817    NaN\n",
       "1141   NaN\n",
       "187    NaN\n",
       "977    NaN\n",
       "667    NaN\n",
       "982    NaN\n",
       "744    NaN\n",
       "269    NaN\n",
       "207    NaN\n",
       "254    NaN\n",
       "859    NaN\n",
       "1259   NaN\n",
       "690    NaN\n",
       "715    NaN\n",
       "783    NaN\n",
       "1117   NaN\n",
       "887    NaN\n",
       "192    NaN\n",
       "1060   NaN\n",
       "1012   NaN\n",
       "897    NaN\n",
       "        ..\n",
       "421    NaN\n",
       "524    NaN\n",
       "462    NaN\n",
       "954    NaN\n",
       "1321   NaN\n",
       "1281   NaN\n",
       "1430   NaN\n",
       "583    NaN\n",
       "1414   NaN\n",
       "415    NaN\n",
       "280    NaN\n",
       "587    NaN\n",
       "1133   NaN\n",
       "261    NaN\n",
       "1084   NaN\n",
       "704    NaN\n",
       "208    NaN\n",
       "942    NaN\n",
       "1008   NaN\n",
       "718    NaN\n",
       "479    NaN\n",
       "99     NaN\n",
       "680    NaN\n",
       "71     NaN\n",
       "324    NaN\n",
       "206    NaN\n",
       "1408   NaN\n",
       "1142   NaN\n",
       "131    NaN\n",
       "264    NaN\n",
       "Name: rating, Length: 1151, dtype: float64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2892"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = Xtest.shape[1]\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# define the model\n",
    "def define_model(n_words):\n",
    "    # define network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    # compile network\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_211 (Dense)            (None, 50)                144650    \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,803\n",
      "Trainable params: 144,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671    NaN\n",
       "444    NaN\n",
       "1212   NaN\n",
       "1144   NaN\n",
       "332    NaN\n",
       "1196   NaN\n",
       "570    NaN\n",
       "1338   NaN\n",
       "392    NaN\n",
       "817    NaN\n",
       "1141   NaN\n",
       "187    NaN\n",
       "977    NaN\n",
       "667    NaN\n",
       "982    NaN\n",
       "744    NaN\n",
       "269    NaN\n",
       "207    NaN\n",
       "254    NaN\n",
       "859    NaN\n",
       "1259   NaN\n",
       "690    NaN\n",
       "715    NaN\n",
       "783    NaN\n",
       "1117   NaN\n",
       "887    NaN\n",
       "192    NaN\n",
       "1060   NaN\n",
       "1012   NaN\n",
       "897    NaN\n",
       "        ..\n",
       "421    NaN\n",
       "524    NaN\n",
       "462    NaN\n",
       "954    NaN\n",
       "1321   NaN\n",
       "1281   NaN\n",
       "1430   NaN\n",
       "583    NaN\n",
       "1414   NaN\n",
       "415    NaN\n",
       "280    NaN\n",
       "587    NaN\n",
       "1133   NaN\n",
       "261    NaN\n",
       "1084   NaN\n",
       "704    NaN\n",
       "208    NaN\n",
       "942    NaN\n",
       "1008   NaN\n",
       "718    NaN\n",
       "479    NaN\n",
       "99     NaN\n",
       "680    NaN\n",
       "71     NaN\n",
       "324    NaN\n",
       "206    NaN\n",
       "1408   NaN\n",
       "1142   NaN\n",
       "131    NaN\n",
       "264    NaN\n",
       "Name: rating, Length: 1151, dtype: float64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-334-2c6d6c717a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, to_categorical(y_train_docs), epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 67.361111\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(Xtest, to_categorical(y_test_docs), verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode training data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mode(Xtrain, ytrain, Xtest, ytest):\n",
    "    scores = list()\n",
    "    n_repeats = 10\n",
    "    n_words = Xtest.shape[1]\n",
    "    for i in range(n_repeats):\n",
    "        # define network\n",
    "        model = define_model(n_words)\n",
    "        # fit network\n",
    "        model.fit(Xtrain, ytrain, epochs=100, verbose=0)\n",
    "        # evaluate\n",
    "        _, acc = model.evaluate(Xtest, to_categorical(y_test_docs), verbose=0)\n",
    "        scores.append(acc)\n",
    "        print('%d accuracy: %s' % ((i+1), acc))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.7152777777777778\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.71875\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 accuracy: 0.7083333333333334\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.7083333333333334\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_117 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.7152777777777778\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6 accuracy: 0.7326388888888888\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.7083333333333334\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.7013888888888888\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9 accuracy: 0.7222222222222222\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.7048611111111112\n",
      "          binary\n",
      "count  10.000000\n",
      "mean    0.713542\n",
      "std     0.009295\n",
      "min     0.701389\n",
      "25%     0.708333\n",
      "50%     0.711806\n",
      "75%     0.717882\n",
      "max     0.732639\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_129 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.7118055555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.7222222222222222\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 accuracy: 0.7222222222222222\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.7152777777777778\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.7256944444444444\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6 accuracy: 0.71875\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_141 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.7083333333333334\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.7152777777777778\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9 accuracy: 0.7256944444444444\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.71875\n",
      "          binary      count\n",
      "count  10.000000  10.000000\n",
      "mean    0.713542   0.718403\n",
      "std     0.009295   0.005775\n",
      "min     0.701389   0.708333\n",
      "25%     0.708333   0.715278\n",
      "50%     0.711806   0.718750\n",
      "75%     0.717882   0.722222\n",
      "max     0.732639   0.725694\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_149 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_157 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_159 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.7361111111111112\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_163 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9 accuracy: 0.3680555555555556\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_167 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.7013888888888888\n",
      "          binary      count      tfidf\n",
      "count  10.000000  10.000000  10.000000\n",
      "mean    0.713542   0.718403   0.438194\n",
      "std     0.009295   0.005775   0.148092\n",
      "min     0.701389   0.708333   0.368056\n",
      "25%     0.708333   0.715278   0.368056\n",
      "50%     0.711806   0.718750   0.368056\n",
      "75%     0.717882   0.722222   0.368056\n",
      "max     0.732639   0.725694   0.736111\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.6736111111111112\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.6666666666666666\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_173 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 accuracy: 0.6666666666666666\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.6631944444444444\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_177 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.6666666666666666\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_179 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6 accuracy: 0.6736111111111112\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_181 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.6736111111111112\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_183 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.6631944444444444\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_185 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 accuracy: 0.6701388888888888\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 50)                144750    \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 144,903\n",
      "Trainable params: 144,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.6770833333333334\n",
      "          binary      count      tfidf       freq\n",
      "count  10.000000  10.000000  10.000000  10.000000\n",
      "mean    0.713542   0.718403   0.438194   0.669444\n",
      "std     0.009295   0.005775   0.148092   0.004856\n",
      "min     0.701389   0.708333   0.368056   0.663194\n",
      "25%     0.708333   0.715278   0.368056   0.666667\n",
      "50%     0.711806   0.718750   0.368056   0.668403\n",
      "75%     0.717882   0.722222   0.368056   0.673611\n",
      "max     0.732639   0.725694   0.736111   0.677083\n"
     ]
    }
   ],
   "source": [
    "# run experiment\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = DataFrame()\n",
    "for mode in modes:\n",
    "    # prepare data for mode\n",
    "    Xtrain, Xtest = prepare_data(xtrain_docs, xtest_docs, mode)\n",
    "    # evaluate model on data for mode\n",
    "    results[mode] = evaluate_mode(Xtrain, to_categorical(y_train_docs), Xtest, to_categorical(y_test_docs))\n",
    "    # summarize results\n",
    "    # Comparing Word Scoring Methods\n",
    "    print(results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGGBJREFUeJzt3X+QHGd95/H3x2vLNrbKyBEsoB9eObcuFKTCjrdEcXZ8K4iEqpJIqZAjEqlDTkQW7iybIwUVuUTZjnxyCagjd8GqwMbS4eOClMOpcy2gQxiswScDzq7OMtaPyKwFV1pdqpJYtmB9iqWVv/fH9Mrt8UrTq+3d2Znn86qa2u6n+2k982j2M88+09OtiMDMzNJwSaMbYGZmU8ehb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZgkpFPqSVkg6ImlQ0oYxtv+ZpP3Z4zlJL+W2nc1t6yuz8WZmNj6q941cSW3Ac8AyYAjoB9ZExKHz7H8ncFNE/GG2PhwRVxdt0OzZs6Ojo6Po7g3z8ssvc9VVVzW6GS3D/Vku92d5mqUv9+3b908R8ZZ6+11a4FhLgMGIOAogaSewChgz9IE1wL1FG1qro6ODgYGBi60+ZSqVCt3d3Y1uRstwf5bL/VmeZulLSf+nyH5FpnfmAMdy60NZ2Vj/6HXAAuDxXPEVkgYk/UjSbxdplJmZTY4iI/3xWA08EhFnc2XXRcRxSdcDj0t6NiKez1eS1AP0ALS3t1OpVEpuVvmGh4ebop3Nwv1ZLvdneVqtL4uE/nFgXm59blY2ltXAHfmCiDie/TwqqQLcBDxfs08v0AvQ1dUVzfCnVLP8ydcs3J/lcn+Wp9X6ssj0Tj/QKWmBpBlUg/0NZ+FIeicwC/hhrmyWpMuz5dnALZz/swAzM5tkdUf6ETEiaT2wG2gDtkfEQUmbgIGIGH0DWA3sjNefDrQQ+LKkV6m+wWw531k/ZmY2+QrN6UfELmBXTdk9Nev3jVHvB8DiCbTPzMZhx44dbN68mcOHD7Nw4UI2btzImjVrGt0sm0bK/iDXzBpkx44dbNy4kW3btnH27Fna2tpYt24dgIPfzvFlGMZpx44dLFq0iPe///0sWrSIHTt2NLpJZgBs3ryZbdu2sXTpUi699FKWLl3Ktm3b2Lx5c6ObZtOIR/rj4JGUTWeHDx/m1ltvfV3ZrbfeyuHDhxvUIpuOPNIfB4+kbDpbuHAhe/fufV3Z3r17WbhwYYNaZNORQ38cPJKy6Wzjxo2sW7eOPXv2MDIywp49e1i3bh0bN25sdNNsGvH0zjiMjqSWLl16rswjKZsuRqcY77zzznNn72zevNlTj/Y6HumPg0dSNt2tWbOGAwcO8L3vfY8DBw448O0NPNIfB4+kzKzZOfTHac2aNaxZs6blrscxmSSVdqx6938wswvz9I5Nuoio+7juT75ZaD8zmxiP9MdQ5sgUWnd0+u4//Q4nT50p7XgdG75VynGuufIynrl3eSnHMms1Dv0xFAnpjg3f4mdbfmMKWjN9nTx1prQ+KHO6rKw3D7NWlFToe2RarpkLN7D44Q3lHfDhcg4zcyFA2m/IZueTVOh7ZFquXxze0ugmjOmaKy9rdBPMpq2kQt/KVeb0lqfLzKZGUqHv6QgzS11Sof+Lw1s8vWNmSUsq9KHkgP12eR/ktrKip8Dqs/X3adXTX82mSqHQl7QC+M9U75H7UERsqdn+Z8DoVcjeBLw1It6cbVsLfCbb9h8ioqRJkfHzHHRjFAlqf8O5HL5dotVTN/QltQFbgWXAENAvqS9/g/OI+GRu/zuBm7Lla4F7gS4ggH1Z3RdLfRZm5pv8WCFFLsOwBBiMiKMRcRrYCay6wP5rgNF7CH4AeCwiTmRB/xiwYiINNrOx+SY/VkSR6Z05wLHc+hDwnrF2lHQdsAB4/AJ154y/mVOrzDlo8Dy0TQ3f5MeKKPuD3NXAIxFxdjyVJPUAPQDt7e1UKpWSmzU+e/bsqbvP8PAwV199daHjNfr5NIPh4WH30wTNnz+fBx98kJtuuulcfz799NPMnz/ffTsBrfbaLBL6x4F5ufW5WdlYVgN31NTtrqlbqa0UEb1AL0BXV1c0wwd6/uCxXO7PiXvggQfOzelfccUVRARf/OIXeeCBB9y3E9Bqr80iod8PdEpaQDXEVwMfrt1J0juBWcAPc8W7gQckzcrWlwN3T6jFZjYm3+THiqgb+hExImk91QBvA7ZHxEFJm4CBiOjLdl0N7IzcBHZEnJB0P9U3DoBNEXGi3KdgZqN8kx+rp9CcfkTsAnbVlN1Ts37feepuB7ZfZPvMzKxEvnOWmVlCHPpmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJSS5m6iYmY0qenHFoprh4ooe6ZtZsiKi7uO6P/lmof2aIfDBI30za1Hv/tPvcPLUmVKOVdZtVq+58jKeuXd5Kce6WA59M2tJJ0+dKeWWpmVex6jUe3RfJE/vmJklxCN9M2tJMxduYPHDG8o52MPlHGbmQoCJ//UxEQ59M2tJvzi8pdFNeINrrrys0U1w6JtZayoyn+9TNs3MElLkNMw9e/a01CmbDn0zs4Q49M3MElIo9CWtkHRE0qCkMT8Ol/QhSYckHZT0tVz5WUn7s0ffWHXNzGxq1P0gV1IbsBVYBgwB/ZL6IuJQbp9O4G7gloh4UdJbc4c4FRE3ltxuMzO7CEVG+kuAwYg4GhGngZ3Aqpp9/gjYGhEvAkTEP5TbTDMzK0ORUzbnAMdy60PAe2r2uQFA0pNAG3BfRHw723aFpAFgBNgSEY/W/gOSeoAegPb2diqVynieQ0MMDw83RTubhfuzXO7P8rRaX5Z1nv6lQCfQDcwFnpC0OCJeAq6LiOOSrgcel/RsRDyfrxwRvUAvQFdXV5R1nYvJVOb1OMz9WTb3Z3larS+LTO8cB+bl1udmZXlDQF9EnImInwLPUX0TICKOZz+PAhXgpgm22czMLlKR0O8HOiUtkDQDWA3UnoXzKNVRPpJmU53uOSpplqTLc+W3AIcwM7OGqDu9ExEjktYDu6nO12+PiIOSNgEDEdGXbVsu6RBwFvh0RLwg6V8CX5b0KtU3mC35s37MzGxqFZrTj4hdwK6asntyywH8cfbI7/MDYPHEm2lmZmXwN3LNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIQ59M7OEOPTNzBLi0DczS0ih0Je0QtIRSYOSNpxnnw9JOiTpoKSv5crXSvpJ9lhbVsPNzGz86t4jV1IbsBVYBgwB/ZL68jc4l9QJ3A3cEhEvSnprVn4tcC/QBQSwL6v7YvlPxczM6iky0l8CDEbE0Yg4DewEVtXs80fA1tEwj4h/yMo/ADwWESeybY8BK8ppupmZjVfdkT4wBziWWx8C3lOzzw0Akp4E2oD7IuLb56k7p/YfkNQD9AC0t7dTqVQKNr9xhoeHm6KdzcL9WS73Z3larS+LhH7R43QC3cBc4AlJi4tWjoheoBegq6sruru7S2rW5KlUKjRDO5uF+7Nc7s/ytFpfFpneOQ7My63PzcryhoC+iDgTET8FnqP6JlCkrpmZTZEiod8PdEpaIGkGsBroq9nnUaqjfCTNpjrdcxTYDSyXNEvSLGB5VmZmZg1Qd3onIkYkraca1m3A9og4KGkTMBARfbwW7oeAs8CnI+IFAEn3U33jANgUEScm44mYmVl9heb0I2IXsKum7J7ccgB/nD1q624Htk+smWZmVgZ/I9fMLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhBQKfUkrJB2RNChpwxjbb5f0j5L2Z4+P5radzZXX3lDdzMymUN175EpqA7YCy4AhoF9SX0Qcqtn1ryNi/RiHOBURN068qWZmNlFFRvpLgMGIOBoRp4GdwKrJbZaZmU2GuiN9YA5wLLc+BLxnjP0+KOk24DngkxExWucKSQPACLAlIh6trSipB+gBaG9vp1KpFH8GDTI8PNwU7WwW7s9yuT/L02p9WST0i/gGsCMiXpH0MeBh4H3Ztusi4rik64HHJT0bEc/nK0dEL9AL0NXVFd3d3SU1a/JUKhWaoZ3Nwv1ZLvdneVqtL4tM7xwH5uXW52Zl50TECxHxSrb6EHBzbtvx7OdRoALcNIH2mpnZBBQJ/X6gU9ICSTOA1cDrzsKR9Pbc6krgcFY+S9Ll2fJs4Bag9gNgMzObInWndyJiRNJ6YDfQBmyPiIOSNgEDEdEH3CVpJdV5+xPA7Vn1hcCXJb1K9Q1myxhn/ZiZ2RQpNKcfEbuAXTVl9+SW7wbuHqPeD4DFE2yjmZmVxN/INTNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLSKHQl7RC0hFJg5I2jLH9dkn/KGl/9vhobttaST/JHmvLbLyZmY1P3dslSmoDtgLLgCGgX1LfGPe6/euIWF9T91rgXqALCGBfVvfFUlpvZmbjUmSkvwQYjIijEXEa2AmsKnj8DwCPRcSJLOgfA1ZcXFPNzGyiioT+HOBYbn0oK6v1QUk/lvSIpHnjrGtmZlOg7vROQd8AdkTEK5I+BjwMvK9oZUk9QA9Ae3s7lUqlpGZNnuHh4aZoZ7Nwf5bL/VmeVuvLIqF/HJiXW5+blZ0TES/kVh8CPper211Tt1L7D0REL9AL0NXVFd3d3bW7TDuVSoVmaGezcH+Wy/1ZnlbryyLTO/1Ap6QFkmYAq4G+/A6S3p5bXQkczpZ3A8slzZI0C1ielZmZWQPUHelHxIik9VTDug3YHhEHJW0CBiKiD7hL0kpgBDgB3J7VPSHpfqpvHACbIuLEJDwPMzMroNCcfkTsAnbVlN2TW74buPs8dbcD2yfQRjMzK4m/kWtmlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQgqFvqQVko5IGpS04QL7fVBSSOrK1jsknZK0P3t8qayGm5nZ+NW9R66kNmArsAwYAvol9UXEoZr9ZgKfAJ6qOcTzEXFjSe01M7MJKDLSXwIMRsTRiDgN7ARWjbHf/cBngX8usX1mZlaiIqE/BziWWx/Kys6R9KvAvIj41hj1F0h6WtL3Jf3axTfVzMwmqu70Tj2SLgG+ANw+xua/B+ZHxAuSbgYelfSuiPh5zTF6gB6A9vZ2KpXKRJs16YaHh5uinc3C/Vku92d5Wq0vi4T+cWBebn1uVjZqJrAIqEgCeBvQJ2llRAwArwBExD5JzwM3AAP5fyAieoFegK6uruju7r6oJzOVKpUKzdDOZuH+LJf7szyt1pdFpnf6gU5JCyTNAFYDfaMbI+JkRMyOiI6I6AB+BKyMiAFJb8k+CEbS9UAncLT0Z2FmZoXUHelHxIik9cBuoA3YHhEHJW0CBiKi7wLVbwM2SToDvAp8PCJOlNFwMzMbv0Jz+hGxC9hVU3bPefbtzi3/DfA3E2ifmZmVyN/INTNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhhUJf0gpJRyQNStpwgf0+KCkkdeXK7s7qHZH0gTIabWZmF6fuPXIltQFbgWXAENAvqS8iDtXsNxP4BPBUruxXgNXAu4B3AN+VdENEnC3vKZiZWVFFRvpLgMGIOBoRp4GdwKox9rsf+Czwz7myVcDOiHglIn4KDGbHMzOzBigS+nOAY7n1oazsHEm/CsyLiG+Nt66ZmU2dutM79Ui6BPgCcPsEjtED9AC0t7dTqVQm2qxJNzw83BTtbBbuz3K5P8vTan1ZJPSPA/Ny63OzslEzgUVARRLA24A+SSsL1AUgInqBXoCurq7o7u4u/gwapFKp0AztbBbuz3K5P8vTan1ZZHqnH+iUtEDSDKofzPaNboyIkxExOyI6IqID+BGwMiIGsv1WS7pc0gKgE/jb0p+FmZkVUnekHxEjktYDu4E2YHtEHJS0CRiIiL4L1D0o6b8Dh4AR4A6fuWNm1jiF5vQjYhewq6bsnvPs212zvhnYfJHtMzOzEvkbuWZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUImfBMVMyvH4ocXl3vAh8s71LNrny3vYNZQDn2zaaLMYG21G39YeTy9Y2aWEIe+mVlCHPpmZglx6JuZJaRQ6EtaIemIpEFJG8bY/nFJz0raL2mvpF/JyjskncrK90v6UtlPwMzMiqt79o6kNmArsAwYAvol9UXEodxuX4uIL2X7rwS+AKzItj0fETeW22wzM7sYRUb6S4DBiDgaEaeBncCq/A4R8fPc6lVAlNdEMzMrS5HQnwMcy60PZWWvI+kOSc8DnwPuym1aIOlpSd+X9GsTaq2ZmU1IaV/OioitwFZJHwY+A6wF/h6YHxEvSLoZeFTSu2r+MkBSD9CTrQ5LOlJWuybRbOCfGt2IFuL+LJf7szzN0pfXFdmpSOgfB+bl1udmZeezE/gLgIh4BXglW96X/SVwAzCQrxARvUBvkQZPF5IGIqKr0e1oFe7Pcrk/y9NqfVlkeqcf6JS0QNIMYDXQl99BUmdu9TeAn2Tlb8k+CEbS9UAncLSMhpuZ2fjVHelHxIik9cBuoA3YHhEHJW0CBiKiD1gv6deBM8CLVKd2AG4DNkk6A7wKfDwiTkzGEzEzs/oU4RNtLoaknmxaykrg/iyX+7M8rdaXDn0zs4T4MgxmZglJOvSzy0QcGKP8odFLSdj0IunfS3pTo9vRKJLeLOnf5dY/L+lg9vPjkj4yRp3Xvc4l7ZD0Y0mfnKp2T2eS7pJ0WNJfNbotUyHp6R1JHcA3I2LRJB3/0ogYmYxjp0rSz4CuiGiG86ZLV/ualXQSuDYizhapI+ltwN6I+BeT39rmIOnvgF+PiKFcWcv+7iY90s9cKumvsnf6RyS9SVJFUheApGFJmyU9I+lHktqz8t+S9FT2bePv5srvk/RVSU8CX5X0hKRz1x7KLkj37oY80yki6SPZSPKZrC86JD2elX1P0vxsv69I+t1cveHsZ3f2f/CIpL/L/n8k6S7gHcAeSXsa8+wabgvwy9kFDB8Drgb2Sfq97LX3KQBJN2f9/wxwR67+d4A5Wf3kvyGfXQTyeuB/SjpZ87vblv0F1Z+9dj+W1ZGkB1W9COV3Je3Kv46nvYhI9gF0UL1O0C3Z+nbgU0CF6miSbPtvZcufAz6TLc/itb+UPgr8x2z5PmAfcGW2vhb4T9nyDVRPc234c5/EPn0X8BwwO1u/FvgGsDZb/0Pg0Wz5K8Dv5uoOZz+7gZNUvwh4CfBD4NZs289Gj53iI3vNHqjts2z5PuBT2fKPgduy5c+P1qmt78drr6kxfnd7cr/vl1P9UukC4HeAx6iewv4O4KX863i6PzzSh2MR8WS2/N+AW2u2nwa+mS3vo/pLA9VA2i3pWeDTVMNuVF9EnMqWvw78pqTLqAbeV0pt/fTzPuDrkU2/RPV7Ge8FvpZt/ypv7OOx/G1EDEXEq8B+Xut3q0PSm4E3R8QTWdFXG9meJpP/3V0OfETSfuAp4JeofsH0NmBHRJyNiP8LPN6Ypl4ch/4brwhau34msrd64CyvfaHti8CDEbEY+BhwRa7Oy+cOFvH/qI4KVgEfApL4sKigEbLXoKRLgBm5ba/klvP9bjaZXs4tC7gzIm7MHgsi4juNalhZHPowX9J7s+UPA3sL1ruG165BtPZCOwIPAX8O9EfEi+NvYlN5HPjXkn4JQNK1wA+oXr4D4PeB/5Ut/wy4OVteCVxW4Pi/AGaW1dgmVPf5R8RLwEuSRv+i+v1Jb1Vr2g382+yvdCTdIOkq4Ang97I5/7cDSxvZyPFy6MMR4A5Jh6nO0/9FwXr3AV+XtI86V+CLiH3Az4H/MoF2NoWIOAhsBr6ffYj4BeBO4A8k/Rj4N8Anst3/EvhX2X7v5fWjrPPpBb6d6ge5EfEC8KSkA5I+f4Fd/4DqVW/3Ux2x2vg9BBwC/nd2yuuXqf7F+T+oXl/sEPBfqX7m1DSSPmVzqkh6B9UPh9+ZzVGbWYuQ9BWqp8Q+0ui2FOGR/iTLvizzFLDRgW9mjeaRvplZQjzSNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwh/x/HMsWTXCnXxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Predict New Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify a review as negative or positive\n",
    "def predict_sentiment(review, vocab, tokenizer, model):\n",
    "    # clean\n",
    "#     tokens = clean_doc(review)\n",
    "    \n",
    "    tokens = clean_document(text)\n",
    "    print(tokens)\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    # convert to line\n",
    "    line = ' '.join(tokens)\n",
    "    # encode\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    # predict sentiment\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    max_index = np.argmax(yhat[0])\n",
    "    print(yhat[0])\n",
    "    print(yhat[0][max_index])\n",
    "    # retrieve predicted percentage and label\n",
    "    percent_pos = yhat[0][max_index]\n",
    "    if max_index == 0 : \n",
    "        return (percent_pos), '0'\n",
    "    \n",
    "    if max_index == 1 : \n",
    "        return (percent_pos), '1'\n",
    "    if max_index == 2 : \n",
    "        return (percent_pos), '2'\n",
    "    return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leg', 'getting', 'hell', 'lot', 'pain', 'whihch', 'imaginable', 'blood', 'due', 'pain']\n",
      "[5.8799511e-04 8.5197535e-05 2.6998878e-02]\n",
      "0.026998878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.026998878, '2')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test positive text\n",
    "text = \"my leg is getting hell lot of pain whihch is imaginable blood due to pain!!\"\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "percent, sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leg', 'paining', 'alot', 'severe', 'couldnt', 'bear']\n",
      "[0.0011202  0.00935899 0.00075021]\n",
      "0.009358989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009358989, '1')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test positive text\n",
    "text = \"my leg is paining alot and it is severe, couldn't bear any more\"\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "percent, sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leg', 'paining', 'alot', 'severe', 'couldnt', 'bear']\n",
      "[0.0011202  0.00935899 0.00075021]\n",
      "0.009358989\n",
      "Review: [my leg is paining alot and it is severe, couldn't bear any more]\n",
      "Sentiment: 1 (0.936%)\n",
      "['bad', 'movie']\n",
      "[4.3933624e-03 5.6821592e-02 1.1326434e-06]\n",
      "0.056821592\n",
      "Review: [This is a bad movie.]\n",
      "Sentiment: 1 (5.682%)\n"
     ]
    }
   ],
   "source": [
    "# test positive text\n",
    "# text = 'Best movie ever! It was great, I recommend it.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))\n",
    "# test negative text\n",
    "text = 'This is a bad movie.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 500, input_length=max_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2947"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(s.split()) for s in xtrain_docs])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2947"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(set(vocab))\n",
    "len(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Embedding , Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 104, 500)          1473500   \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 97, 32)            128032    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 41, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 13, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,619,943\n",
      "Trainable params: 1,619,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define modela\n",
    "model = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = tokenizer.texts_to_sequences(xtrain_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# integer encode and pad documents\n",
    "def encode_docs(tokenizer, max_length, docs):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(docs)\n",
    "    # pad sequences\n",
    "    padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain  = encode_docs(tokenizer, max_length, xtrain_docs)\n",
    "Xtest  = encode_docs(tokenizer, max_length, xtest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 104, 500)          1473500   \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 97, 32)            128032    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 41, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 13, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,619,943\n",
      "Trainable params: 1,619,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1151, 1151)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain_docs) , len(y_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 7s - loss: 1.0954 - acc: 0.4023\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.0279 - acc: 0.5039\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.8612 - acc: 0.5491\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.6786 - acc: 0.6238\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5634 - acc: 0.6733\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.5292 - acc: 0.6742\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4688 - acc: 0.7011\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.4353 - acc: 0.7037\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.4166 - acc: 0.7142\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.4046 - acc: 0.7220\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4113 - acc: 0.7237\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4055 - acc: 0.7289\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3992 - acc: 0.7202\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3994 - acc: 0.7298\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.4038 - acc: 0.7289\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3983 - acc: 0.7324\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3995 - acc: 0.7298\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3963 - acc: 0.7333\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3952 - acc: 0.7315\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7315\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.3959 - acc: 0.7341\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3952 - acc: 0.7333\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3952 - acc: 0.7298\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3942 - acc: 0.7272\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3954 - acc: 0.7298\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3961 - acc: 0.7281\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3949 - acc: 0.7272\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3945 - acc: 0.7298\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3937 - acc: 0.7307\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3943 - acc: 0.7298\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3941 - acc: 0.7307\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3939 - acc: 0.7298\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3935 - acc: 0.7315\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3933 - acc: 0.7315\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3932 - acc: 0.7315\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.4380 - acc: 0.7228\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.5849 - acc: 0.6977\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5072 - acc: 0.6968\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.4386 - acc: 0.7133\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4111 - acc: 0.7255\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4006 - acc: 0.7289\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3977 - acc: 0.7298\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3970 - acc: 0.7298\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3967 - acc: 0.7298\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3967 - acc: 0.7298\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3964 - acc: 0.7298\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3965 - acc: 0.7289\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7298\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7298\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7298\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3958 - acc: 0.7298\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3953 - acc: 0.7298\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4186 - acc: 0.7281\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4013 - acc: 0.7281\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3973 - acc: 0.7289\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3985 - acc: 0.7281\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3964 - acc: 0.7289\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3961 - acc: 0.7289\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7289\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7289\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7289\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.3960 - acc: 0.7289\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3959 - acc: 0.7289\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7289\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7289\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7289\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3956 - acc: 0.7289\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3959 - acc: 0.7289\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3972 - acc: 0.7289\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3987 - acc: 0.7281\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3966 - acc: 0.7289\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3960 - acc: 0.7289\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7289\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3958 - acc: 0.7289\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7289\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3957 - acc: 0.7289\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3956 - acc: 0.7289\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3956 - acc: 0.7289\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3956 - acc: 0.7289\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7281\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7281\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7289\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3955 - acc: 0.7281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e3bdb7d30>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, to_categorical(y_train_docs), epochs=100, verbose=2)\n",
    "# save the model\n",
    "# model.save('model_nightingale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_tokenizer_file(object_, filename):\n",
    "    # saving\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(object_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_tokenizer_file(filename):\n",
    "    # loading\n",
    "    with open(filename, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        return tokenizer\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7f8e30d84748>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_tokenizer_file(tokenizer, 'tokenizer.pkl')\n",
    "tokenizer = load_tokenizer_file('tokenizer.pkl')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(data, filename):\n",
    "    dump(data,filename)\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: train_nightingale.pkl\n",
      "Saved: test_nightingale.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "# save a dataset to file\n",
    "def save_dataset(dataset, filename):\n",
    "    dump(dataset, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    # load and clean all reviews\n",
    "#     train_docs, ytrain = load_clean_dataset(True)\n",
    "#     test_docs, ytest = load_clean_dataset(False)\n",
    "# save training datasets\n",
    "save_dataset([Xtrain, to_categorical(y_train_docs)], 'train_nightingale.pkl')\n",
    "save_dataset([Xtest, to_categorical(y_test_docs)], 'test_nightingale.pkl')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "# load a clean dataset\n",
    "def load_dataset(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "trainLines, trainLabels = load_dataset('train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This tutorial is divided into the following parts:\n",
    "# 1. Word Embeddings + CNN = Text Classi\f",
    "cation\n",
    "# 2. Use a Single Layer CNN Architecture\n",
    "# 3. Dial in CNN Hyperparameters\n",
    "# 4. Consider Character-Level CNNs\n",
    "# 5. Consider Deeper CNNs for Classi\f",
    "cation\n",
    "\n",
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 300)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 300)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 300)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    \n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(3, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2894"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLines\n",
    "Xtrain  = encode_docs(tokenizer, max_length, xtrain_docs)\n",
    "Xtest  = encode_docs(tokenizer, max_length, xtest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = max_length\n",
    "from numpy import array\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1151, 1151, 1151)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainLabels) , len(xtrain_docs)  , len(y_train_docs)\n",
    "# len(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = to_categorical(y_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1151"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 104)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 104)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 104)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 104, 300)     868200      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 104, 300)     868200      input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 104, 300)     868200      input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 101, 32)      38432       embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 99, 32)       57632       embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 97, 32)       76832       embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 101, 32)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 99, 32)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 97, 32)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 50, 32)       0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 49, 32)       0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 48, 32)       0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 1600)         0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 1568)         0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 1536)         0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4704)         0           flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_197 (Dense)               (None, 10)           47050       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_198 (Dense)               (None, 3)            33          dense_197[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,824,579\n",
      "Trainable params: 2,824,579\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "1151/1151 [==============================] - 9s 8ms/step - loss: 1.0806 - acc: 0.4118\n",
      "Epoch 2/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.9508 - acc: 0.5413\n",
      "Epoch 3/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.5590 - acc: 0.8288\n",
      "Epoch 4/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.1679 - acc: 0.9557\n",
      "Epoch 5/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0944 - acc: 0.9661\n",
      "Epoch 6/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9713\n",
      "Epoch 7/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0649 - acc: 0.9687\n",
      "Epoch 8/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0570 - acc: 0.9722\n",
      "Epoch 9/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0519 - acc: 0.9748\n",
      "Epoch 10/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0516 - acc: 0.9731\n",
      "Epoch 11/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0484 - acc: 0.9731\n",
      "Epoch 12/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0468 - acc: 0.9713\n",
      "Epoch 13/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0451 - acc: 0.9748\n",
      "Epoch 14/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9739\n",
      "Epoch 15/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0460 - acc: 0.9705\n",
      "Epoch 16/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0459 - acc: 0.9722\n",
      "Epoch 17/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0425 - acc: 0.9722\n",
      "Epoch 18/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0431 - acc: 0.9731\n",
      "Epoch 19/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0438 - acc: 0.9739\n",
      "Epoch 20/20\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0479 - acc: 0.9757\n"
     ]
    }
   ],
   "source": [
    "trainX = encode_text(tokenizer, xtrain_docs, max_length)\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "# fit model\n",
    "history = model.fit([trainX,trainX,trainX], array(trainLabels), epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "# save the model\n",
    "model.save('model_multi_nightingale.h5')\n",
    "model = load_model('model_multi_nightingale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX  = encode_docs(tokenizer, max_length, xtest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.65\n",
      "Test Accuracy: 70.49\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training dataset\n",
    "_, acc = model.evaluate([trainX,trainX,trainX],to_categorical(y_train_docs), verbose=2)\n",
    "print('Train Accuracy: %.2f' % (acc*100))\n",
    "# evaluate model on test dataset dataset\n",
    "_, acc = model.evaluate([testX,testX,testX],to_categorical(y_test_docs), verbose=2)\n",
    "print('Test Accuracy: %.2f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vocab with weights for embedding space generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import   asarray,zeros\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "# f = open('/home/surya/cs224n-Squad-Project/data/glove.6B.100d.txt')\n",
    "f = open('/root/data/glove/glove.6B.300d.txt')\n",
    "\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2894"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female, 55 years, 75 kg and obese. hypertensive 160/110 Hg. doctor prescribes olmesartan , suffering severe headache'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2948"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(clean_doc_voc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"0.41711,-0.10176,0.058147,-0.18332,-0.44458,-0.17852,-0.34392,-0.077147,0.58521,-0.52752,1.4831,0.9531,-0.027201,-0.31748,-0.23046,-0.24083,0.22548,-0.12685,-0.17578,-0.34924,0.5168,0.86818,-0.018579,1.2228,-0.52477,-0.26369,0.25925,-0.059529,0.27063,0.13036,-0.67677,0.48313,-0.16343,-0.069899,0.92846,-0.44196,-0.078755,0.5246,-0.59577,-0.1659,0.35194,0.30031,-0.50711,0.29111,-0.26332,-1.0523,-0.31061,-0.077155,-0.16019,0.26994,-1.1042,0.16292,0.79396,-0.77135,-0.95157,-0.55992,0.69163,0.021495,0.44292,-0.69881, 0.73889,-0.1064,-0.44058,0.17116,0.39109,0.043652, 1.2835,0.29026,0.51037,-0.19631,0.036696  -0.74017,-0.0035271 -0.54918,-0.25002,0.15853,0.71764,-0.28083, 0.42292,-0.89855,0.99665,-0.65188,-0.11919,-0.28617,-0.85273,0.55656,-0.23601,-0.43822,0.36317,0.45724, 0.38596,0.59233,1.4355,1.4563,1.1801,0.32987, 0.84998,-0.29444,-0.039114,0.39534\".split(\",\")\n",
    "\n",
    "a = np.array(a)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix = zeros((vocab_size, 100))\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "#     print((word,i),embedding_vector)\n",
    "if embedding_vector is not None:\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ADD USER DEFINED EMBEDDING FROM GLOVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2948, 300)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884400"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit \n",
    "# np.isnan(data)[np.isnan(data) == False].size\n",
    "np.isnan(embedding_matrix)[np.isnan(embedding_matrix) == False].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2947"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_matrix\n",
    "np.sum(~embedding_matrix.any(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.0071524 ,  0.36849999,  0.030004  , ...,  0.49214   ,\n",
       "        -0.14947   , -0.32574001]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, max_length , custom_embed = True):\n",
    "    model = Sequential()\n",
    "#     model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "#     model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length , trainable=False))\n",
    "    model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    print(\"Hello!!!!!!!!!\")\n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "#     model.layers[0].set_weights([embedding_matrix])\n",
    "#     model.layers[0].trainable = False\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-259-95010fed5cda>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-259-95010fed5cda>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    if typeToLoad==\"glove\":\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#    #load different embedding file from Kaggle depending on which embedding \n",
    "#         #matrix we are going to experiment with\n",
    "#         if typeToLoad==\"glove\":\n",
    "#             EMBEDDING_FILE='../input/glove-twitter/glove.twitter.27B.25d.txt'\n",
    "#             embed_size = 25\n",
    "#         elif(typeToLoad==\"word2vec\"):\n",
    "#             word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "#             embed_size = 300\n",
    "#         elif(typeToLoad==\"fasttext\"):\n",
    "#             EMBEDDING_FILE='../input/fasttext/wiki.simple.vec'\n",
    "#             embed_size = 300\n",
    "\n",
    "#         if(typeToLoad==\"glove\" or typeToLoad==\"fasttext\" ):\n",
    "#             embeddings_index = dict()\n",
    "#             #Transfer the embedding weights into a dictionary by iterating through every line of the file.\n",
    "#             f = open(EMBEDDING_FILE)\n",
    "#             for line in f:\n",
    "#                 #split up line into an indexed array\n",
    "#                 values = line.split()\n",
    "#                 #first index is word\n",
    "#                 word = values[0]\n",
    "#                 #store the rest of the values in the array as a new array\n",
    "#                 coefs = np.asarray(values[1:], dtype='float32')\n",
    "#                 embeddings_index[word] = coefs #50 dimensions\n",
    "#             f.close()\n",
    "#             print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "#         else:\n",
    "#             embeddings_index = dict()\n",
    "#             for word in word2vecDict.wv.vocab:\n",
    "#                 embeddings_index[word] = word2vecDict.word_vec(word)\n",
    "#             print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "            \n",
    "#         gc.collect()\n",
    "#         #We get the mean and standard deviation of the embedding weights so that we could maintain the \n",
    "#         #same statistics for the rest of our own random generated weights. \n",
    "#         all_embs = np.stack(list(embeddings_index.values()))\n",
    "#         emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        \n",
    "#         nb_words = len(tokenizer.word_index)\n",
    "#         #We are going to set the embedding size to the pretrained dimension as we are replicating it.\n",
    "#         #the size will be Number of Words in Vocab X Embedding Size\n",
    "#         embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "#         gc.collect()\n",
    "\n",
    "#         #With the newly created embedding matrix, we'll fill it up with the words that we have in both \n",
    "#         #our own dictionary and loaded pretrained embedding. \n",
    "#         embeddedCount = 0\n",
    "#         for word, i in tokenizer.word_index.items():\n",
    "#             i-=1\n",
    "#             #then we see if this word is in glove's dictionary, if yes, get the corresponding weights\n",
    "#             embedding_vector = embeddings_index.get(word)\n",
    "#             #and store inside the embedding matrix that we will train later on.\n",
    "#             if embedding_vector is not None: \n",
    "#                 embedding_matrix[i] = embedding_vector\n",
    "#                 embeddedCount+=1\n",
    "#         print('total embedded:',embeddedCount,'common words')\n",
    "        \n",
    "#         del(embeddings_index)\n",
    "#         gc.collect()\n",
    "        \n",
    "#         #finally, return the embedding matrix\n",
    "#         return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!!!!!!!!!\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 104, 300)          884400    \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 97, 32)            76832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 10)                15370     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 976,635\n",
      "Trainable params: 976,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1035 samples, validate on 116 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 1.0827 - acc: 0.4145 - val_loss: 1.0444 - val_acc: 0.4828\n",
      "Epoch 2/20\n",
      " - 1s - loss: 1.0127 - acc: 0.5024 - val_loss: 0.9543 - val_acc: 0.5345\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.7676 - acc: 0.6705 - val_loss: 0.7647 - val_acc: 0.6724\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.3811 - acc: 0.9034 - val_loss: 0.9629 - val_acc: 0.5948\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.1875 - acc: 0.9440 - val_loss: 0.9001 - val_acc: 0.6810\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.1344 - acc: 0.9614 - val_loss: 1.0668 - val_acc: 0.6207\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.1025 - acc: 0.9720 - val_loss: 0.7223 - val_acc: 0.7414\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.0796 - acc: 0.9739 - val_loss: 0.6727 - val_acc: 0.7414\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.0694 - acc: 0.9720 - val_loss: 0.7453 - val_acc: 0.7414\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0645 - acc: 0.9797 - val_loss: 0.6725 - val_acc: 0.7500\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0697 - acc: 0.9700 - val_loss: 0.8788 - val_acc: 0.7155\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0593 - acc: 0.9729 - val_loss: 0.7607 - val_acc: 0.7328\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0618 - acc: 0.9739 - val_loss: 0.7076 - val_acc: 0.7500\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0568 - acc: 0.9768 - val_loss: 0.7200 - val_acc: 0.7586\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0474 - acc: 0.9739 - val_loss: 0.6973 - val_acc: 0.7672\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0607 - acc: 0.9778 - val_loss: 0.7046 - val_acc: 0.7241\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0512 - acc: 0.9758 - val_loss: 0.7139 - val_acc: 0.7500\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0505 - acc: 0.9768 - val_loss: 0.7201 - val_acc: 0.7414\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0517 - acc: 0.9768 - val_loss: 0.8019 - val_acc: 0.7500\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0496 - acc: 0.9749 - val_loss: 0.7815 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e3453ea90>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = define_model(vocab_size,max_length,True)\n",
    "model.fit(Xtrain, to_categorical(y_train_docs), epochs=20, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This tutorial is divided into the following parts:\n",
    "# 1. Word Embeddings + CNN = Text Classi\f",
    "cation\n",
    "# 2. Use a Single Layer CNN Architecture\n",
    "# 3. Dial in CNN Hyperparameters\n",
    "# 4. Consider Character-Level CNNs\n",
    "# 5. Consider Deeper CNNs for Classi\f",
    "cation\n",
    "\n",
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 300)(inputs1)\n",
    "#     embedding1 = Embedding(vocab_size,  300, weights=[embedding_matrix], trainable=False)(inputs1)\n",
    "#         model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length , trainable=False))\n",
    "\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 300)(inputs2)\n",
    "#     embedding2 = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 300)(inputs3)\n",
    "#     embedding3 = Embedding(vocab_size, 100)(embedding3)\n",
    "#     embedding3 = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(inputs3)\n",
    "\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    \n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(3, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = encode_text(tokenizer, xtrain_docs, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 104)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 104)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 104)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 104, 300)     884400      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 104, 300)     884400      input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 104, 300)     884400      input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 101, 32)      38432       embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 99, 32)       57632       embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 97, 32)       76832       embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 101, 32)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 99, 32)       0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 97, 32)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 50, 32)       0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 49, 32)       0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 48, 32)       0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 1600)         0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 1568)         0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 1536)         0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4704)         0           flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_209 (Dense)               (None, 10)           47050       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_210 (Dense)               (None, 3)            33          dense_209[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,873,179\n",
      "Trainable params: 2,873,179\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1151/1151 [==============================] - 10s 9ms/step - loss: 1.0647 - acc: 0.4544\n",
      "Epoch 2/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.8248 - acc: 0.6099\n",
      "Epoch 3/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.5022 - acc: 0.7011\n",
      "Epoch 4/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.3476 - acc: 0.7672\n",
      "Epoch 5/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.2106 - acc: 0.9314\n",
      "Epoch 6/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.1054 - acc: 0.9652\n",
      "Epoch 7/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0798 - acc: 0.9713\n",
      "Epoch 8/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0648 - acc: 0.9705\n",
      "Epoch 9/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0587 - acc: 0.9739\n",
      "Epoch 10/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0637 - acc: 0.9739\n",
      "Epoch 11/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0563 - acc: 0.9713\n",
      "Epoch 12/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0547 - acc: 0.9757\n",
      "Epoch 13/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0559 - acc: 0.9748\n",
      "Epoch 14/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0506 - acc: 0.9748\n",
      "Epoch 15/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0538 - acc: 0.9713\n",
      "Epoch 16/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0515 - acc: 0.9670\n",
      "Epoch 17/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0462 - acc: 0.9757\n",
      "Epoch 18/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0452 - acc: 0.9713\n",
      "Epoch 19/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0505 - acc: 0.9679\n",
      "Epoch 20/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0492 - acc: 0.9731\n",
      "Epoch 21/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9739\n",
      "Epoch 22/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0431 - acc: 0.9731\n",
      "Epoch 23/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0448 - acc: 0.9705\n",
      "Epoch 24/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9757\n",
      "Epoch 25/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0432 - acc: 0.9748\n",
      "Epoch 26/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9783\n",
      "Epoch 27/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0489 - acc: 0.9765\n",
      "Epoch 28/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0533 - acc: 0.9748\n",
      "Epoch 29/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0434 - acc: 0.9705\n",
      "Epoch 30/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0430 - acc: 0.9713\n",
      "Epoch 31/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0410 - acc: 0.9713\n",
      "Epoch 32/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9713\n",
      "Epoch 33/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0432 - acc: 0.9679\n",
      "Epoch 34/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0417 - acc: 0.9705\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0396 - acc: 0.9696\n",
      "Epoch 36/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0422 - acc: 0.9757\n",
      "Epoch 37/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0393 - acc: 0.9757\n",
      "Epoch 38/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0409 - acc: 0.9661\n",
      "Epoch 39/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0446 - acc: 0.9748\n",
      "Epoch 40/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0391 - acc: 0.9748\n",
      "Epoch 41/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0426 - acc: 0.9783\n",
      "Epoch 42/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0402 - acc: 0.9722\n",
      "Epoch 43/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0421 - acc: 0.9722\n",
      "Epoch 44/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0482 - acc: 0.9687\n",
      "Epoch 45/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0547 - acc: 0.9731\n",
      "Epoch 46/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.1735 - acc: 0.9505\n",
      "Epoch 47/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0727 - acc: 0.9739\n",
      "Epoch 48/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0482 - acc: 0.9765\n",
      "Epoch 49/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0553 - acc: 0.9739\n",
      "Epoch 50/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9705\n",
      "Epoch 51/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0429 - acc: 0.9713\n",
      "Epoch 52/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0392 - acc: 0.9739\n",
      "Epoch 53/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0429 - acc: 0.9696\n",
      "Epoch 54/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9687\n",
      "Epoch 55/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9713\n",
      "Epoch 56/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0395 - acc: 0.9731\n",
      "Epoch 57/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0394 - acc: 0.9722\n",
      "Epoch 58/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0399 - acc: 0.9722\n",
      "Epoch 59/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0385 - acc: 0.9739\n",
      "Epoch 60/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0402 - acc: 0.9722\n",
      "Epoch 61/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9739\n",
      "Epoch 62/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0391 - acc: 0.9731\n",
      "Epoch 63/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0433 - acc: 0.9679\n",
      "Epoch 64/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0405 - acc: 0.9739\n",
      "Epoch 65/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0412 - acc: 0.9757\n",
      "Epoch 66/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0396 - acc: 0.9739\n",
      "Epoch 67/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0424 - acc: 0.9713\n",
      "Epoch 68/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0402 - acc: 0.9739\n",
      "Epoch 69/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0399 - acc: 0.9705\n",
      "Epoch 70/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0410 - acc: 0.9696\n",
      "Epoch 71/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0396 - acc: 0.9739\n",
      "Epoch 72/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0416 - acc: 0.9696\n",
      "Epoch 73/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0411 - acc: 0.9722\n",
      "Epoch 74/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0385 - acc: 0.9774\n",
      "Epoch 75/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0439 - acc: 0.9731\n",
      "Epoch 76/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0394 - acc: 0.9783\n",
      "Epoch 77/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0401 - acc: 0.9713\n",
      "Epoch 78/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0416 - acc: 0.9713\n",
      "Epoch 79/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0418 - acc: 0.9705\n",
      "Epoch 80/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0407 - acc: 0.9739\n",
      "Epoch 81/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9731\n",
      "Epoch 82/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0439 - acc: 0.9731\n",
      "Epoch 83/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9731\n",
      "Epoch 84/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0409 - acc: 0.9722\n",
      "Epoch 85/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0405 - acc: 0.9748\n",
      "Epoch 86/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0404 - acc: 0.9748\n",
      "Epoch 87/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0392 - acc: 0.9757\n",
      "Epoch 88/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0422 - acc: 0.9739\n",
      "Epoch 89/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0401 - acc: 0.9696\n",
      "Epoch 90/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0437 - acc: 0.9722\n",
      "Epoch 91/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9739\n",
      "Epoch 92/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0403 - acc: 0.9757\n",
      "Epoch 93/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9765\n",
      "Epoch 94/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0408 - acc: 0.9705\n",
      "Epoch 95/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0420 - acc: 0.9748\n",
      "Epoch 96/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0401 - acc: 0.9722\n",
      "Epoch 97/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0401 - acc: 0.9757\n",
      "Epoch 98/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0411 - acc: 0.9739\n",
      "Epoch 99/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0398 - acc: 0.9757\n",
      "Epoch 100/100\n",
      "1151/1151 [==============================] - 3s 2ms/step - loss: 0.0402 - acc: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e36cdce10>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = encode_text(tokenizer, xtrain_docs, max_length)\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "# fit model\n",
    "model.fit([trainX,trainX,trainX], array(trainLabels), epochs=100, batch_size=16 , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model_path = tf.contrib.saved_model.save_keras_model(model, \"./saved_models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--. 1 root root  7040824 May 14 16:58 model_98.h5\n",
      "-rw-r--r--. 1 root root 20628648 May 14 18:21 model.h5\n",
      "-rw-r--r--. 1 root root 20628648 May 14 18:24 model_multi.h5\n",
      "-rw-r--r--. 1 root root  2649064 May 20 17:27 model_nightingale.h5\n",
      "-rw-r--r--. 1 root root 33960888 May 22 15:27 model_multi_nightingale.h5\n",
      "/home/surya\n"
     ]
    }
   ],
   "source": [
    "! ls -ltr /home/surya/model_multi_nightingale.h5\n",
    "/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-288-51d5b7ab328e>:6: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-51d5b7ab328e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"export_path\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         outputs={'output': keras_model.output})\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/saved_model/simple_save.py\u001b[0m in \u001b[0;36msimple_save\u001b[0;34m(session, export_dir, inputs, outputs, legacy_init_op)\u001b[0m\n\u001b[1;32m     79\u001b[0m   signature_def_map = {\n\u001b[1;32m     80\u001b[0m       \u001b[0msignature_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SERVING_SIGNATURE_DEF_KEY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m           \u001b[0msignature_def_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m   }\n\u001b[1;32m     83\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py\u001b[0m in \u001b[0;36mpredict_signature_def\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   signature_inputs = {key: utils.build_tensor_info(tensor)\n\u001b[0;32m--> 205\u001b[0;31m                       for key, tensor in inputs.items()}\n\u001b[0m\u001b[1;32m    206\u001b[0m   signature_outputs = {key: utils.build_tensor_info(tensor)\n\u001b[1;32m    207\u001b[0m                        for key, tensor in outputs.items()}\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   signature_inputs = {key: utils.build_tensor_info(tensor)\n\u001b[0;32m--> 205\u001b[0;31m                       for key, tensor in inputs.items()}\n\u001b[0m\u001b[1;32m    206\u001b[0m   signature_outputs = {key: utils.build_tensor_info(tensor)\n\u001b[1;32m    207\u001b[0m                        for key, tensor in outputs.items()}\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/saved_model/utils_impl.py\u001b[0m in \u001b[0;36mbuild_tensor_info\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[1;32m     57\u001b[0m   tensor_info = meta_graph_pb2.TensorInfo(\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m       tensor_shape=tensor.get_shape().as_proto())\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "with tf.keras.backend.get_session() as sess:\n",
    "    tf.saved_model.simple_save(\n",
    "        sess,\n",
    "        \"export_path\",\n",
    "        inputs={'input': keras_model.input},\n",
    "        outputs={'output': keras_model.output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.keras.experimental' has no attribute 'export_saved_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-7c96284a5e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/surya/saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.experimental' has no attribute 'export_saved_model'"
     ]
    }
   ],
   "source": [
    "keras.experimental.export_saved_model(model, '/home/surya/saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to a SavedModel\n",
    "keras.experimental.export_saved_model(model, 'path_to_saved_model')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = keras.experimental.load_from_saved_model('path_to_saved_model')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-846bc2fc0d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mlflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.keras.log_model(model, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-88fa60e8f88e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models_keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mlflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "# model\n",
    "mlflow.keras.save_model(model, \"models_keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import mlflow\n",
    ">>> # Build, compile, and train your model\n",
    ">>> keras_model = ...\n",
    ">>> keras_model_path = ...\n",
    ">>> keras_model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    ">>> results = keras_model.fit(\n",
    "...     x_train, y_train, epochs=20, batch_size = 128, validation_data=(x_val, y_val))\n",
    "... # Save the model as an MLflow Model\n",
    ">>> mlflow.keras.save_model(keras_model, keras_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
