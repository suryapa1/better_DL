{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surya\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas import DataFrame\n",
    "from pandas.io.json import json_normalize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low       588\n",
      "high      521\n",
      "medium    453\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"/home/surya/Nightingale_Chat.xlsx\",sheet_name = \"All\", header=0)\n",
    "print(df.rating.value_counts())\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           patient_chat rating\n",
      "0     female, 55 years, 75 kg and obese. hypertensiv...   high\n",
      "1     I'm 22 and male and I have gotten terrible mig...   high\n",
      "2     My wife is constantly suffering from high bloo...   high\n",
      "3     I get head aches multiple time times a week I'...   high\n",
      "4     I recently suffered a substantial loss of belo...   high\n",
      "1557   Hello John,How can I help to you Low headache...    low\n",
      "1558   Hello John,How can I help to you headache Com...    low\n",
      "1559   Hello John,How can I help to you Sever headac...    low\n",
      "1560   Hello John,How can I help to you I take toomu...    low\n",
      "1561   Hello John,How can I help to you What causes ...    low\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df.head(), df.tail()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "discard_words = {'not' , 'no'}\n",
    "stop_words = stop_words - discard_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my', 'y', 'why', 'after', 'should', 'hadn', 'theirs', 't', 'our', 'yourself', 'or', 'when', 'off', 'i', 'had', 'can', 'shan', 'these', 'until', \"couldn't\", 'is', 'ain', 'she', 'ma', 'weren', 'under', 'd', 'this', \"mightn't\", 'there', 'each', \"wouldn't\", 'over', 'such', 'shouldn', \"aren't\", 'now', 'during', 'an', \"that'll\", 'are', 'will', 'both', 'on', 'the', 'didn', 'those', 'aren', 'which', 'their', 'more', \"you'll\", 'needn', 'into', 'up', 'don', \"shouldn't\", 'its', 'below', 'himself', 'of', 'you', 'and', 'for', 'm', 'in', 'here', 'your', \"isn't\", \"weren't\", \"don't\", \"you'd\", 'between', 'itself', 'because', 'isn', 'any', \"doesn't\", 'we', 'hers', 'mightn', \"shan't\", \"haven't\", 'mustn', 'it', 'who', 'were', \"mustn't\", 've', 'at', 'once', \"needn't\", \"wasn't\", 'against', 'out', 'further', 'where', 'whom', 'than', 'do', 'but', 're', 'did', 'haven', \"she's\", 'other', 'above', 'being', 'few', 'so', 'him', 'all', 'wasn', 'before', 'been', 'how', 'them', 'that', 'a', 'about', \"should've\", \"hasn't\", 'me', 'am', \"didn't\", \"you've\", 'he', 'by', 'ourselves', \"hadn't\", 'themselves', 'down', 'very', 'while', 'just', 'hasn', \"you're\", 'nor', 'to', 'they', 'll', \"it's\", 'again', 'doing', 'his', 'what', 'from', \"won't\", 'too', 'then', 'was', 'have', 'if', 'wouldn', 'having', 'same', 's', 'couldn', 'myself', 'as', 'most', 'only', 'yours', 'doesn', 'won', 'ours', 'has', 'with', 'own', 'does', 'through', 'be', 'yourselves', 'some', 'herself', 'her', 'o'}\n"
     ]
    }
   ],
   "source": [
    "type(stop_words)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'nor',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18752"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "293*64"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# list(stop_words) in \n",
    "print('not' in list(stop_words))\n",
    "print('not' in list(stop_words))\n",
    "\n",
    "# stop_words = stop_words.remove('not')\n",
    "# print('not' in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    with open(filename) as f:\n",
    "        d = json.load(f)\n",
    "        df = DataFrame(d)\n",
    "        f.close()\n",
    "    return df\n",
    "\n",
    "punc_ = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(doc) :\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = doc.lower().split()\n",
    "#     tokens = [w for w in tokens if '@' not in w]\n",
    "    \n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha() or word.isalnum()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [word for word in tokens if word not in punc_]\n",
    "    tokens = [re.sub('[^A-Za-z0-9]+', '', word)  for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "def preprocess_documents(docs):\n",
    "    clean_docs = [clean_document(doc) for doc in docs]\n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  5 11:13:17 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro P5000        Off  | 00000000:61:00.0 Off |                  Off |\r\n",
      "| 26%   39C    P0    39W / 180W |      0MiB / 16278MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df.patient_chat)\n",
    "clean_docs = preprocess_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vocobulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3074\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(doc,vocab):\n",
    "    vocab.update(doc)\n",
    "    return vocab\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(clean_docs, vocab):\n",
    "    for doc in clean_docs:\n",
    "        vocab = add_doc_to_vocab(doc, vocab)\n",
    "    return vocab\n",
    "\n",
    "vocab = process_docs(clean_docs, vocab)\n",
    "\n",
    "# keep tokens with a min occurrence\n",
    "min_occurrence = 2\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurrence]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOtal Vocobulary : 2960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "    # convert lines to a single blob of text\n",
    "    data = '\\n'.join(lines)\n",
    "    # open file\n",
    "    file = open(filename, 'w')\n",
    "    # write text\n",
    "    file.write(data)\n",
    "    # close file\n",
    "    file.close()\n",
    "    \n",
    "# save tokens to a vocabulary file\n",
    "save_list(tokens, 'nightingale_vocab.txt')\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(doc, vocab):\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in doc if w in vocab]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vocabulary\n",
    "vocab_filename = 'nightingale_vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = set(vocab.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_doc_voc = []\n",
    "for doc in clean_docs:\n",
    "    clean_doc_voc.append(doc_to_line(doc, vocab))\n",
    "    \n",
    "df[\"clean_doc_voc\"] = clean_doc_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating  = df.rating.map({'low':0, 'medium':1, 'high' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X.index,y,test_size=0.2)\n",
    "train, test = train_test_split(df[[\"clean_doc_voc\",\"rating\" ]], test_size=0.2)\n",
    "\n",
    "xtrain_docs , y_train_docs= train[\"clean_doc_voc\"] , train[\"rating\"]\n",
    "xtest_docs , y_test_docs= test[\"clean_doc_voc\"] , test[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3022\n",
      "3022\n"
     ]
    }
   ],
   "source": [
    "# encode data\n",
    "tokenizer = create_tokenizer(xtrain_docs)\n",
    "Xtrain = tokenizer.texts_to_matrix(xtrain_docs, mode='freq' )\n",
    "print(len(tokenizer.word_index))\n",
    "Xtest = tokenizer.texts_to_matrix(xtest_docs, mode='freq')\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3022"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1249, 3023), (1249,))\n",
      "((313,), (313,))\n"
     ]
    }
   ],
   "source": [
    "print((Xtrain.shape ,y_train_docs.shape))\n",
    "print((xtest_docs.shape, y_test_docs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3022"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831     0\n",
       "961     0\n",
       "1042    0\n",
       "742     1\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_docs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3023"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = Xtest.shape[1]\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3023"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# define the model\n",
    "def define_model(n_words):\n",
    "    # define network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3023"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3074"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb64155a128>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, to_categorical(y_train_docs), epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"nightingale_freq.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_tokenizer_file(object_, filename):\n",
    "    # saving\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(object_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_tokenizer_file(filename):\n",
    "    # loading\n",
    "    with open(filename, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        return tokenizer\n",
    "    return null\n",
    "save_tokenizer_file(tokenizer,\"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.536741\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(Xtest, to_categorical(y_test_docs), verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode training data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mode(Xtrain, ytrain, Xtest, ytest):\n",
    "    scores = list()\n",
    "    n_repeats = 10\n",
    "    n_words = Xtest.shape[1]\n",
    "    for i in range(n_repeats):\n",
    "        # define network\n",
    "        model = define_model(n_words)\n",
    "        # fit network\n",
    "        model.fit(Xtrain, ytrain, epochs=100, verbose=0)\n",
    "        # evaluate\n",
    "        _, acc = model.evaluate(Xtest, to_categorical(y_test_docs), verbose=0)\n",
    "        scores.append(acc)\n",
    "        print('%d accuracy: %s' % ((i+1), acc))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.7156549513149566\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.7028754016461845\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 accuracy: 0.7124600631360429\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.7124600661829257\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.6996805117533992\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6 accuracy: 0.6996805134672708\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.7092651780040119\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.7028754016461845\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9 accuracy: 0.7188498394938704\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.7028754016461845\n",
      "          binary\n",
      "count  10.000000\n",
      "mean    0.707668\n",
      "std     0.006943\n",
      "min     0.699681\n",
      "25%     0.702875\n",
      "50%     0.706070\n",
      "75%     0.712460\n",
      "max     0.718850\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_117 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_129 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.4185303512472695\n",
      "          binary         count\n",
      "count  10.000000  1.000000e+01\n",
      "mean    0.707668  4.185304e-01\n",
      "std     0.006943  5.851389e-17\n",
      "min     0.699681  4.185304e-01\n",
      "25%     0.702875  4.185304e-01\n",
      "50%     0.706070  4.185304e-01\n",
      "75%     0.712460  4.185304e-01\n",
      "max     0.718850  4.185304e-01\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_141 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_149 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9 accuracy: 0.4185303512472695\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.4185303512472695\n",
      "          binary         count         tfidf\n",
      "count  10.000000  1.000000e+01  1.000000e+01\n",
      "mean    0.707668  4.185304e-01  4.185304e-01\n",
      "std     0.006943  5.851389e-17  5.851389e-17\n",
      "min     0.699681  4.185304e-01  4.185304e-01\n",
      "25%     0.702875  4.185304e-01  4.185304e-01\n",
      "50%     0.706070  4.185304e-01  4.185304e-01\n",
      "75%     0.712460  4.185304e-01  4.185304e-01\n",
      "max     0.718850  4.185304e-01  4.185304e-01\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 accuracy: 0.6900958489305296\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_157 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 accuracy: 0.6773162962148745\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_159 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 accuracy: 0.6773162962148745\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 accuracy: 0.6900958489305296\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_163 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 accuracy: 0.6932907371094432\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6 accuracy: 0.6677316316781333\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_167 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "7 accuracy: 0.6805111843937883\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8 accuracy: 0.6805111813469055\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 accuracy: 0.6741214063220893\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_173 (Dense)            (None, 50)                151200    \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 151,353\n",
      "Trainable params: 151,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 accuracy: 0.6741214080359608\n",
      "          binary         count         tfidf       freq\n",
      "count  10.000000  1.000000e+01  1.000000e+01  10.000000\n",
      "mean    0.707668  4.185304e-01  4.185304e-01   0.680511\n",
      "std     0.006943  5.851389e-17  5.851389e-17   0.008249\n",
      "min     0.699681  4.185304e-01  4.185304e-01   0.667732\n",
      "25%     0.702875  4.185304e-01  4.185304e-01   0.674920\n",
      "50%     0.706070  4.185304e-01  4.185304e-01   0.678914\n",
      "75%     0.712460  4.185304e-01  4.185304e-01   0.687700\n",
      "max     0.718850  4.185304e-01  4.185304e-01   0.693291\n"
     ]
    }
   ],
   "source": [
    "# run experiment\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = DataFrame()\n",
    "for mode in modes:\n",
    "    # prepare data for mode\n",
    "    Xtrain, Xtest = prepare_data(xtrain_docs, xtest_docs, mode)\n",
    "    # evaluate model on data for mode\n",
    "    results[mode] = evaluate_mode(Xtrain, to_categorical(y_train_docs), Xtest, to_categorical(y_test_docs))\n",
    "    # summarize results\n",
    "    # Comparing Word Scoring Methods\n",
    "    print(results.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Predict New Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify a review as negative or positive\n",
    "def predict_sentiment(review, vocab, tokenizer, model):\n",
    "    # clean\n",
    "#     tokens = clean_doc(review)\n",
    "    \n",
    "    tokens = clean_document(text)\n",
    "    print(tokens)\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    # convert to line\n",
    "    line = ' '.join(tokens)\n",
    "    # encode\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    # predict sentiment\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    max_index = np.argmax(yhat[0])\n",
    "    print(yhat[0])\n",
    "    print(yhat[0][max_index])\n",
    "    # retrieve predicted percentage and label\n",
    "    percent_pos = yhat[0][max_index]\n",
    "    if max_index == 0 : \n",
    "        return (percent_pos), '0'\n",
    "    \n",
    "    if max_index == 1 : \n",
    "        return (percent_pos), '1'\n",
    "    if max_index == 2 : \n",
    "        return (percent_pos), '2'\n",
    "    return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leg', 'getting', 'hell', 'lot', 'pain', 'whihch', 'un', 'imaginable', 'blood', 'due', 'pain']\n",
      "[0.07367576 0.18888555 0.6332315 ]\n",
      "0.6332315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6332315, '2')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test positive text\n",
    "text = \"my leg is getting hell lot of pain whihch is un imaginable blood due to pain!!\"\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "percent, sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leg', 'paining', 'alot', 'severe', 'couldnt', 'bear']\n",
      "[0.11229624 0.42249006 0.29615688]\n",
      "0.42249006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42249006, '1')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test positive text\n",
    "text = \"my leg is paining alot and it is severe, couldn't bear any more\"\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "percent, sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leg', 'paining', 'alot', 'severe', 'couldnt', 'bear']\n",
      "[0.11229624 0.42249006 0.29615688]\n",
      "0.42249006\n",
      "Review: [my leg is paining alot and it is severe, couldn't bear any more]\n",
      "Sentiment: 1 (42.249%)\n",
      "['bad', 'movie']\n",
      "[0.5570071  0.25768185 0.03741346]\n",
      "0.5570071\n",
      "Review: [This is a bad movie.]\n",
      "Sentiment: 0 (55.701%)\n"
     ]
    }
   ],
   "source": [
    "# test positive text\n",
    "# text = 'Best movie ever! It was great, I recommend it.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))\n",
    "# test negative text\n",
    "text = 'This is a bad movie.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text, sentiment, percent*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2883"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3074"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(s.split()) for s in xtrain_docs])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3074"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(set(vocab))\n",
    "len(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Embedding , Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 103, 300)          922200    \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 96, 32)            76832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 41, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 13, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,017,443\n",
      "Trainable params: 1,017,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define modela\n",
    "model = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = tokenizer.texts_to_sequences(xtrain_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# integer encode and pad documents\n",
    "def encode_docs(tokenizer, max_length, docs):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(docs)\n",
    "    # pad sequences\n",
    "    padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain  = encode_docs(tokenizer, max_length, xtrain_docs)\n",
    "Xtest  = encode_docs(tokenizer, max_length, xtest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 103, 300)          922200    \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 96, 32)            76832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 41, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 13, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,017,443\n",
      "Trainable params: 1,017,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249, 1249)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain_docs) , len(y_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 5s - loss: 1.0788 - acc: 0.4171\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.9544 - acc: 0.5324\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.7532 - acc: 0.6918\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.5635 - acc: 0.7942\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.3820 - acc: 0.8575\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2980 - acc: 0.8935\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2138 - acc: 0.9279\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.1514 - acc: 0.9488\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.1162 - acc: 0.9552\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.1188 - acc: 0.9576\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0923 - acc: 0.9672\n",
      "Epoch 12/20\n",
      " - 1s - loss: nan - acc: 0.9047\n",
      "Epoch 13/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 14/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 15/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 16/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 17/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 18/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 19/20\n",
      " - 1s - loss: nan - acc: 0.3659\n",
      "Epoch 20/20\n",
      " - 1s - loss: nan - acc: 0.3659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb63f7faf60>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, to_categorical(y_train_docs), epochs=20, verbose=2)\n",
    "# save the model\n",
    "# model.save('model_nightingale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_tokenizer_file(object_, filename):\n",
    "    # saving\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(object_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_tokenizer_file(filename):\n",
    "    # loading\n",
    "    with open(filename, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        return tokenizer\n",
    "    return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "# save the model\n",
    "model.save('ng_model_epch20.h5')\n",
    "# model = load_model('model_multi_nightingale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surya\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7fb63ef5fb00>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_tokenizer_file(tokenizer, 'tokenizer.pkl')\n",
    "tokenizer = load_tokenizer_file('tokenizer.pkl')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(data, filename):\n",
    "    dump(data,filename)\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" Hello John,How can I help to you What causes headaches?please let me know Is it a throbbing headache?  How does bending forward affect your headache?  How would you describe the intensity of your headache?  Do you become frustrated or upset easily?  Have you recently used any drugs in any form?  Do you experience day time sleep?  Do you tend to drink alcohol heavily?  Are you feeling agitated and physically restless? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'johnhow', 'help', 'causes', 'headachesplease', 'let', 'know', 'throbbing', 'headache', 'bending', 'forward', 'affect', 'headache', 'would', 'describe', 'intensity', 'headache', 'become', 'frustrated', 'upset', 'easily', 'recently', 'used', 'drugs', 'form', 'experience', 'day', 'time', 'sleep', 'tend', 'drink', 'alcohol', 'heavily', 'feeling', 'agitated', 'physically', 'restless']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello johnhow help causes headachesplease let know throbbing headache bending forward affect headache would describe intensity headache become frustrated upset easily recently used drugs form experience day time sleep tend drink alcohol heavily feeling agitated physically restless'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = clean_document(text)\n",
    "print(tokens)\n",
    "# filter by vocab\n",
    "tokens = [w for w in tokens if w in vocab]\n",
    "# # convert to line\n",
    "line = ' '.join(tokens)\n",
    "line\n",
    "\n",
    "# # encode\n",
    "# encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "# # predict sentiment\n",
    "# yhat = model.predict(encoded, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_docs = encode_docs(tokenizer, max_length, [line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_arr = model.predict(enc_docs)\n",
    "# output_arr[]\n",
    "output_arr.argmax()\n",
    "output_arr[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, acc = model.evaluate([trainX,trainX,trainX],to_categorical(y_train_docs), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 238,  453,   21, ...,    0,    0,    0],\n",
       "       [ 775,   18,   13, ...,    0,    0,    0],\n",
       "       [ 296,   20,   13, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 163,  652, 1177, ...,    0,    0,    0],\n",
       "       [   2,  140,    2, ...,    0,    0,    0],\n",
       "       [  86,  241,  155, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain  = encode_docs(tokenizer, max_length, xtrain_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: train_nightingale.pkl\n",
      "Saved: test_nightingale.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "# save a dataset to file\n",
    "def save_dataset(dataset, filename):\n",
    "    dump(dataset, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    # load and clean all reviews\n",
    "#     train_docs, ytrain = load_clean_dataset(True)\n",
    "#     test_docs, ytest = load_clean_dataset(False)\n",
    "# save training datasets\n",
    "save_dataset([Xtrain, to_categorical(y_train_docs)], 'train_nightingale.pkl')\n",
    "save_dataset([Xtest, to_categorical(y_test_docs)], 'test_nightingale.pkl')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "# load a clean dataset\n",
    "def load_dataset(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "trainLines, trainLabels = load_dataset('train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Word Embeddings + CNN = Text Classi\f",
    "cation\n",
    "# 2. Use a Single Layer CNN Architecture\n",
    "# 3. Dial in CNN Hyperparameters\n",
    "# 4. Consider Character-Level CNNs\n",
    "# 5. Consider Deeper CNNs for Classi\f",
    "cation\n",
    "\n",
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 300)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 300)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 300)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    \n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(3, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load multichannel.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3023"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    # integer encode\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    # pad encoded sequences\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLines\n",
    "Xtrain  = encode_docs(tokenizer, max_length, xtrain_docs)\n",
    "Xtest  = encode_docs(tokenizer, max_length, xtest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = max_length\n",
    "from numpy import array\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11712, 1249, 1249)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainLabels) , len(xtrain_docs)  , len(y_train_docs)\n",
    "# len(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = to_categorical(y_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 103, 300)     906900      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 103, 300)     906900      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 103, 300)     906900      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 100, 32)      38432       embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 98, 32)       57632       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 96, 32)       76832       embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100, 32)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 98, 32)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96, 32)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 50, 32)       0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 49, 32)       0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 48, 32)       0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1600)         0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1568)         0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1536)         0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4704)         0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 10)           47050       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 3)            33          dense_179[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,940,679\n",
      "Trainable params: 2,940,679\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 103, 300)     906900      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 103, 300)     906900      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 103, 300)     906900      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 100, 32)      38432       embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 98, 32)       57632       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 96, 32)       76832       embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100, 32)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 98, 32)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96, 32)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 50, 32)       0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 49, 32)       0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 48, 32)       0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1600)         0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1568)         0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1536)         0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4704)         0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 10)           47050       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 3)            33          dense_179[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,940,679\n",
      "Trainable params: 2,940,679\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trainX = encode_text(tokenizer, xtrain_docs, max_length)\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1249/1249 [==============================] - 8s 6ms/step - loss: 1.0550 - acc: 0.4412\n",
      "Epoch 2/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.7849 - acc: 0.6733\n",
      "Epoch 3/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.3811 - acc: 0.8647\n",
      "Epoch 4/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.1544 - acc: 0.9472\n",
      "Epoch 5/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0946 - acc: 0.9664\n",
      "Epoch 6/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0836 - acc: 0.9696\n",
      "Epoch 7/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0648 - acc: 0.9744\n",
      "Epoch 8/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0608 - acc: 0.9688\n",
      "Epoch 9/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0497 - acc: 0.9744\n",
      "Epoch 10/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0515 - acc: 0.9728\n",
      "Epoch 11/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0519 - acc: 0.9704\n",
      "Epoch 12/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0460 - acc: 0.9736\n",
      "Epoch 13/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0513 - acc: 0.9744\n",
      "Epoch 14/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0418 - acc: 0.9760\n",
      "Epoch 15/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0439 - acc: 0.9816\n",
      "Epoch 16/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0404 - acc: 0.9776\n",
      "Epoch 17/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0405 - acc: 0.9768\n",
      "Epoch 18/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0432 - acc: 0.9776\n",
      "Epoch 19/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0450 - acc: 0.9784\n",
      "Epoch 20/20\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0382 - acc: 0.9696\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit([trainX,trainX,trainX], array(trainLabels), epochs=20, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ng_model_model_multiinput.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05257658, 0.01467865, 0.01347747]], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([enc_docs,enc_docs,enc_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "# save the model\n",
    "model.save('model_multi_nightingale.h5')\n",
    "model = load_model('model_multi_nightingale.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX  = encode_docs(tokenizer, max_length, xtest_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.52\n",
      "Test Accuracy: 72.52\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training dataset\n",
    "_, acc = model.evaluate([trainX,trainX,trainX],to_categorical(y_train_docs), verbose=2)\n",
    "print('Train Accuracy: %.2f' % (acc*100))\n",
    "# evaluate model on test dataset dataset\n",
    "_, acc = model.evaluate([testX,testX,testX],to_categorical(y_test_docs), verbose=2)\n",
    "print('Test Accuracy: %.2f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vocab with weights for embedding space generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import   asarray,zeros\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "# f = open('/home/surya/cs224n-Squad-Project/data/glove.6B.100d.txt')\n",
    "f = open('/root/data/glove/glove.6B.300d.txt')\n",
    "\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3023"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female, 55 years, 75 kg and obese. hypertensive 160/110 Hg. doctor prescribes olmesartan , suffering severe headache'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(clean_doc_voc)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"0.41711,-0.10176,0.058147,-0.18332,-0.44458,-0.17852,-0.34392,-0.077147,0.58521,-0.52752,1.4831,0.9531,-0.027201,-0.31748,-0.23046,-0.24083,0.22548,-0.12685,-0.17578,-0.34924,0.5168,0.86818,-0.018579,1.2228,-0.52477,-0.26369,0.25925,-0.059529,0.27063,0.13036,-0.67677,0.48313,-0.16343,-0.069899,0.92846,-0.44196,-0.078755,0.5246,-0.59577,-0.1659,0.35194,0.30031,-0.50711,0.29111,-0.26332,-1.0523,-0.31061,-0.077155,-0.16019,0.26994,-1.1042,0.16292,0.79396,-0.77135,-0.95157,-0.55992,0.69163,0.021495,0.44292,-0.69881, 0.73889,-0.1064,-0.44058,0.17116,0.39109,0.043652, 1.2835,0.29026,0.51037,-0.19631,0.036696  -0.74017,-0.0035271 -0.54918,-0.25002,0.15853,0.71764,-0.28083, 0.42292,-0.89855,0.99665,-0.65188,-0.11919,-0.28617,-0.85273,0.55656,-0.23601,-0.43822,0.36317,0.45724, 0.38596,0.59233,1.4355,1.4563,1.1801,0.32987, 0.84998,-0.29444,-0.039114,0.39534\".split(\",\")\n",
    "\n",
    "a = np.array(a)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix = zeros((vocab_size, 100))\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "#     print((word,i),embedding_vector)\n",
    "if embedding_vector is not None:\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ADD USER DEFINED EMBEDDING FROM GLOVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075, 300)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "922500"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit \n",
    "# np.isnan(data)[np.isnan(data) == False].size\n",
    "np.isnan(embedding_matrix)[np.isnan(embedding_matrix) == False].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_matrix\n",
    "np.sum(~embedding_matrix.any(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, max_length , custom_embed = True):\n",
    "    model = Sequential()\n",
    "#     model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "#     model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length , trainable=False))\n",
    "    model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    print(\"Hello!!!!!!!!!\")\n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "#     model.layers[0].set_weights([embedding_matrix])\n",
    "#     model.layers[0].trainable = False\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    #load different embedding file from Kaggle depending on which embedding \n",
    "#         #matrix we are going to experiment with\n",
    "#         if typeToLoad==\"glove\":\n",
    "#             EMBEDDING_FILE='../input/glove-twitter/glove.twitter.27B.25d.txt'\n",
    "#             embed_size = 25\n",
    "#         elif(typeToLoad==\"word2vec\"):\n",
    "#             word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "#             embed_size = 300\n",
    "#         elif(typeToLoad==\"fasttext\"):\n",
    "#             EMBEDDING_FILE='../input/fasttext/wiki.simple.vec'\n",
    "#             embed_size = 300\n",
    "\n",
    "#         if(typeToLoad==\"glove\" or typeToLoad==\"fasttext\" ):\n",
    "#             embeddings_index = dict()\n",
    "#             #Transfer the embedding weights into a dictionary by iterating through every line of the file.\n",
    "#             f = open(EMBEDDING_FILE)\n",
    "#             for line in f:\n",
    "#                 #split up line into an indexed array\n",
    "#                 values = line.split()\n",
    "#                 #first index is word\n",
    "#                 word = values[0]\n",
    "#                 #store the rest of the values in the array as a new array\n",
    "#                 coefs = np.asarray(values[1:], dtype='float32')\n",
    "#                 embeddings_index[word] = coefs #50 dimensions\n",
    "#             f.close()\n",
    "#             print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "#         else:\n",
    "#             embeddings_index = dict()\n",
    "#             for word in word2vecDict.wv.vocab:\n",
    "#                 embeddings_index[word] = word2vecDict.word_vec(word)\n",
    "#             print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "            \n",
    "#         gc.collect()\n",
    "#         #We get the mean and standard deviation of the embedding weights so that we could maintain the \n",
    "#         #same statistics for the rest of our own random generated weights. \n",
    "#         all_embs = np.stack(list(embeddings_index.values()))\n",
    "#         emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        \n",
    "#         nb_words = len(tokenizer.word_index)\n",
    "#         #We are going to set the embedding size to the pretrained dimension as we are replicating it.\n",
    "#         #the size will be Number of Words in Vocab X Embedding Size\n",
    "#         embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "#         gc.collect()\n",
    "\n",
    "#         #With the newly created embedding matrix, we'll fill it up with the words that we have in both \n",
    "#         #our own dictionary and loaded pretrained embedding. \n",
    "#         embeddedCount = 0\n",
    "#         for word, i in tokenizer.word_index.items():\n",
    "#             i-=1\n",
    "#             #then we see if this word is in glove's dictionary, if yes, get the corresponding weights\n",
    "#             embedding_vector = embeddings_index.get(word)\n",
    "#             #and store inside the embedding matrix that we will train later on.\n",
    "#             if embedding_vector is not None: \n",
    "#                 embedding_matrix[i] = embedding_vector\n",
    "#                 embeddedCount+=1\n",
    "#         print('total embedded:',embeddedCount,'common words')\n",
    "        \n",
    "#         del(embeddings_index)\n",
    "#         gc.collect()\n",
    "        \n",
    "#         #finally, return the embedding matrix\n",
    "#         return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!!!!!!!!!\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 103, 300)          922500    \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 96, 32)            76832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 10)                15370     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,014,735\n",
      "Trainable params: 1,014,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1124 samples, validate on 125 samples\n",
      "Epoch 1/80\n",
      " - 7s - loss: 1.0761 - acc: 0.4359 - val_loss: 1.0418 - val_acc: 0.4960\n",
      "Epoch 2/80\n",
      " - 1s - loss: 0.8976 - acc: 0.6254 - val_loss: 0.8907 - val_acc: 0.5840\n",
      "Epoch 3/80\n",
      " - 1s - loss: 0.4491 - acc: 0.8665 - val_loss: 0.8182 - val_acc: 0.6160\n",
      "Epoch 4/80\n",
      " - 1s - loss: 0.1659 - acc: 0.9502 - val_loss: 0.7742 - val_acc: 0.6400\n",
      "Epoch 5/80\n",
      " - 1s - loss: 0.1012 - acc: 0.9689 - val_loss: 0.8378 - val_acc: 0.6240\n",
      "Epoch 6/80\n",
      " - 1s - loss: 0.0894 - acc: 0.9706 - val_loss: 0.8438 - val_acc: 0.6320\n",
      "Epoch 7/80\n",
      " - 1s - loss: 0.0688 - acc: 0.9706 - val_loss: 0.8165 - val_acc: 0.6400\n",
      "Epoch 8/80\n",
      " - 1s - loss: 0.0649 - acc: 0.9715 - val_loss: 0.8751 - val_acc: 0.6480\n",
      "Epoch 9/80\n",
      " - 1s - loss: 0.0627 - acc: 0.9733 - val_loss: 0.8765 - val_acc: 0.6240\n",
      "Epoch 10/80\n",
      " - 1s - loss: 0.0614 - acc: 0.9742 - val_loss: 0.9467 - val_acc: 0.6320\n",
      "Epoch 11/80\n",
      " - 1s - loss: 0.0531 - acc: 0.9715 - val_loss: 0.9521 - val_acc: 0.6400\n",
      "Epoch 12/80\n",
      " - 1s - loss: 0.0529 - acc: 0.9769 - val_loss: 1.0061 - val_acc: 0.6160\n",
      "Epoch 13/80\n",
      " - 1s - loss: 0.0559 - acc: 0.9715 - val_loss: 0.9170 - val_acc: 0.6560\n",
      "Epoch 14/80\n",
      " - 1s - loss: 0.0476 - acc: 0.9778 - val_loss: 0.9968 - val_acc: 0.6400\n",
      "Epoch 15/80\n",
      " - 1s - loss: 0.0481 - acc: 0.9706 - val_loss: 0.9397 - val_acc: 0.6240\n",
      "Epoch 16/80\n",
      " - 1s - loss: 0.0524 - acc: 0.9742 - val_loss: 0.9181 - val_acc: 0.6640\n",
      "Epoch 17/80\n",
      " - 1s - loss: 0.0517 - acc: 0.9760 - val_loss: 1.0296 - val_acc: 0.6320\n",
      "Epoch 18/80\n",
      " - 1s - loss: 0.0459 - acc: 0.9769 - val_loss: 0.9585 - val_acc: 0.6800\n",
      "Epoch 19/80\n",
      " - 1s - loss: 0.0429 - acc: 0.9778 - val_loss: 0.9946 - val_acc: 0.6160\n",
      "Epoch 20/80\n",
      " - 1s - loss: 0.0407 - acc: 0.9760 - val_loss: 1.0554 - val_acc: 0.6240\n",
      "Epoch 21/80\n",
      " - 1s - loss: 0.0412 - acc: 0.9760 - val_loss: 1.0099 - val_acc: 0.6400\n",
      "Epoch 22/80\n",
      " - 1s - loss: 0.0382 - acc: 0.9760 - val_loss: 1.0676 - val_acc: 0.6320\n",
      "Epoch 23/80\n",
      " - 1s - loss: 0.0390 - acc: 0.9751 - val_loss: 1.0408 - val_acc: 0.6320\n",
      "Epoch 24/80\n",
      " - 1s - loss: 0.0387 - acc: 0.9769 - val_loss: 1.0425 - val_acc: 0.6560\n",
      "Epoch 25/80\n",
      " - 1s - loss: 0.0390 - acc: 0.9742 - val_loss: 1.0684 - val_acc: 0.6320\n",
      "Epoch 26/80\n",
      " - 1s - loss: 0.0388 - acc: 0.9742 - val_loss: 1.0848 - val_acc: 0.6320\n",
      "Epoch 27/80\n",
      " - 1s - loss: 0.0390 - acc: 0.9751 - val_loss: 1.0840 - val_acc: 0.6640\n",
      "Epoch 28/80\n",
      " - 1s - loss: 0.0376 - acc: 0.9760 - val_loss: 1.1088 - val_acc: 0.6640\n",
      "Epoch 29/80\n",
      " - 1s - loss: 0.0407 - acc: 0.9733 - val_loss: 1.1628 - val_acc: 0.6320\n",
      "Epoch 30/80\n",
      " - 1s - loss: 0.0395 - acc: 0.9742 - val_loss: 1.1060 - val_acc: 0.6480\n",
      "Epoch 31/80\n",
      " - 1s - loss: 0.0392 - acc: 0.9751 - val_loss: 1.1322 - val_acc: 0.6560\n",
      "Epoch 32/80\n",
      " - 1s - loss: 0.0391 - acc: 0.9751 - val_loss: 1.1128 - val_acc: 0.6720\n",
      "Epoch 33/80\n",
      " - 1s - loss: 0.0374 - acc: 0.9778 - val_loss: 1.1483 - val_acc: 0.6320\n",
      "Epoch 34/80\n",
      " - 1s - loss: 0.0372 - acc: 0.9769 - val_loss: 1.1688 - val_acc: 0.6320\n",
      "Epoch 35/80\n",
      " - 1s - loss: 0.0378 - acc: 0.9786 - val_loss: 1.1445 - val_acc: 0.6640\n",
      "Epoch 36/80\n",
      " - 1s - loss: 0.0373 - acc: 0.9778 - val_loss: 1.1654 - val_acc: 0.6480\n",
      "Epoch 37/80\n",
      " - 1s - loss: 0.0396 - acc: 0.9795 - val_loss: 1.2046 - val_acc: 0.6320\n",
      "Epoch 38/80\n",
      " - 1s - loss: 0.0380 - acc: 0.9778 - val_loss: 1.5533 - val_acc: 0.5360\n",
      "Epoch 39/80\n",
      " - 1s - loss: 0.0401 - acc: 0.9795 - val_loss: 1.2670 - val_acc: 0.6640\n",
      "Epoch 40/80\n",
      " - 1s - loss: 0.0380 - acc: 0.9778 - val_loss: 1.2017 - val_acc: 0.6480\n",
      "Epoch 41/80\n",
      " - 1s - loss: 0.0371 - acc: 0.9751 - val_loss: 1.2342 - val_acc: 0.6480\n",
      "Epoch 42/80\n",
      " - 1s - loss: 0.0366 - acc: 0.9751 - val_loss: 1.2234 - val_acc: 0.6560\n",
      "Epoch 43/80\n",
      " - 1s - loss: 0.0360 - acc: 0.9751 - val_loss: 1.2584 - val_acc: 0.6400\n",
      "Epoch 44/80\n",
      " - 1s - loss: 0.0370 - acc: 0.9742 - val_loss: 1.2507 - val_acc: 0.6400\n",
      "Epoch 45/80\n",
      " - 1s - loss: 0.0364 - acc: 0.9760 - val_loss: 1.2582 - val_acc: 0.6480\n",
      "Epoch 46/80\n",
      " - 1s - loss: 0.0357 - acc: 0.9760 - val_loss: 1.2741 - val_acc: 0.6480\n",
      "Epoch 47/80\n",
      " - 1s - loss: 0.0417 - acc: 0.9751 - val_loss: 1.2524 - val_acc: 0.6480\n",
      "Epoch 48/80\n",
      " - 1s - loss: 0.0362 - acc: 0.9751 - val_loss: 1.3422 - val_acc: 0.6320\n",
      "Epoch 49/80\n",
      " - 1s - loss: 0.0360 - acc: 0.9751 - val_loss: 1.3282 - val_acc: 0.6400\n",
      "Epoch 50/80\n",
      " - 1s - loss: 0.0368 - acc: 0.9760 - val_loss: 1.3272 - val_acc: 0.6320\n",
      "Epoch 51/80\n",
      " - 1s - loss: 0.0367 - acc: 0.9742 - val_loss: 1.3454 - val_acc: 0.6240\n",
      "Epoch 52/80\n",
      " - 1s - loss: 0.0384 - acc: 0.9760 - val_loss: 1.4509 - val_acc: 0.6160\n",
      "Epoch 53/80\n",
      " - 1s - loss: 0.0383 - acc: 0.9733 - val_loss: 1.3756 - val_acc: 0.6320\n",
      "Epoch 54/80\n",
      " - 1s - loss: 0.0379 - acc: 0.9760 - val_loss: 1.3335 - val_acc: 0.6320\n",
      "Epoch 55/80\n",
      " - 1s - loss: 0.0364 - acc: 0.9760 - val_loss: 1.3957 - val_acc: 0.6240\n",
      "Epoch 56/80\n",
      " - 1s - loss: 0.0358 - acc: 0.9742 - val_loss: 1.4004 - val_acc: 0.6240\n",
      "Epoch 57/80\n",
      " - 1s - loss: 0.0356 - acc: 0.9751 - val_loss: 1.4048 - val_acc: 0.6240\n",
      "Epoch 58/80\n",
      " - 1s - loss: 0.0361 - acc: 0.9769 - val_loss: 1.4091 - val_acc: 0.6320\n",
      "Epoch 59/80\n",
      " - 1s - loss: 0.0359 - acc: 0.9742 - val_loss: 1.4345 - val_acc: 0.6400\n",
      "Epoch 60/80\n",
      " - 1s - loss: 0.0359 - acc: 0.9733 - val_loss: 1.4204 - val_acc: 0.6400\n",
      "Epoch 61/80\n",
      " - 1s - loss: 0.0358 - acc: 0.9760 - val_loss: 1.4355 - val_acc: 0.6400\n",
      "Epoch 62/80\n",
      " - 1s - loss: 0.0358 - acc: 0.9769 - val_loss: 1.4219 - val_acc: 0.6320\n",
      "Epoch 63/80\n",
      " - 1s - loss: 0.0358 - acc: 0.9751 - val_loss: 1.4304 - val_acc: 0.6400\n",
      "Epoch 64/80\n",
      " - 1s - loss: 0.0353 - acc: 0.9742 - val_loss: 1.4389 - val_acc: 0.6480\n",
      "Epoch 65/80\n",
      " - 1s - loss: 0.0361 - acc: 0.9733 - val_loss: 1.4323 - val_acc: 0.6480\n",
      "Epoch 66/80\n",
      " - 1s - loss: 0.0372 - acc: 0.9769 - val_loss: 1.6346 - val_acc: 0.6080\n",
      "Epoch 67/80\n",
      " - 1s - loss: 0.0375 - acc: 0.9724 - val_loss: 1.4559 - val_acc: 0.6240\n",
      "Epoch 68/80\n",
      " - 1s - loss: 0.0358 - acc: 0.9760 - val_loss: 1.4867 - val_acc: 0.6480\n",
      "Epoch 69/80\n",
      " - 1s - loss: 0.0349 - acc: 0.9769 - val_loss: 1.5234 - val_acc: 0.6320\n",
      "Epoch 70/80\n",
      " - 1s - loss: 0.0356 - acc: 0.9742 - val_loss: 1.5258 - val_acc: 0.6400\n",
      "Epoch 71/80\n",
      " - 1s - loss: 0.0348 - acc: 0.9751 - val_loss: 1.5103 - val_acc: 0.6560\n",
      "Epoch 72/80\n",
      " - 1s - loss: 0.0351 - acc: 0.9751 - val_loss: 1.5233 - val_acc: 0.6640\n",
      "Epoch 73/80\n",
      " - 1s - loss: 0.0355 - acc: 0.9733 - val_loss: 1.5260 - val_acc: 0.6640\n",
      "Epoch 74/80\n",
      " - 1s - loss: 0.0348 - acc: 0.9742 - val_loss: 1.5572 - val_acc: 0.6240\n",
      "Epoch 75/80\n",
      " - 1s - loss: 0.0351 - acc: 0.9760 - val_loss: 1.5560 - val_acc: 0.6240\n",
      "Epoch 76/80\n",
      " - 1s - loss: 0.0353 - acc: 0.9760 - val_loss: 1.5533 - val_acc: 0.6320\n",
      "Epoch 77/80\n",
      " - 1s - loss: 0.0350 - acc: 0.9769 - val_loss: 1.5551 - val_acc: 0.6240\n",
      "Epoch 78/80\n",
      " - 1s - loss: 0.0352 - acc: 0.9751 - val_loss: 1.5550 - val_acc: 0.6560\n",
      "Epoch 79/80\n",
      " - 1s - loss: 0.0354 - acc: 0.9715 - val_loss: 1.5232 - val_acc: 0.6560\n",
      "Epoch 80/80\n",
      " - 1s - loss: 0.0353 - acc: 0.9742 - val_loss: 1.5538 - val_acc: 0.6400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb630149c18>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = define_model(vocab_size,max_length,True)\n",
    "model.fit(Xtrain, to_categorical(y_train_docs), epochs=80, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt4HPV97/H3V6vVzZJlWZavMrbBxtgkjsHGIYU0pCSpuZO0pZCQhqQJzYWGtEkb0uYQDs/padOTpG1SUkIpCbkQIDQkTuqEGAK0hEuQuVs22BjLkiUbYd2tu/Q9f8xoWcuSvDYa7Wr383oePTs7M7v71Wg1n5n5zfzG3B0RERGAvHQXICIimUOhICIiCQoFERFJUCiIiEiCQkFERBIUCiIikqBQkJxiZt8xs/+T4rx7zOxdUdckkkkUCiIikqBQEJmGzCw/3TVIdlIoSMYJD9v8lZk9Z2aHzOw/zGyemf3CzDrN7H4zq0ia/2Iz22ZmbWb2kJmtSpp2mpk9Fb7uLqBo1GddaGbPhK991MzWpFjjBWb2tJl1mFm9md0wavrZ4fu1hdOvCscXm9lXzazOzNrN7JFw3Dlm1jDGcnhXOHyDmd1jZt83sw7gKjPbYGaPhZ/RZGb/amYFSa8/1cy2mFmLmR0ws78xs/lm1m1mlUnznW5mzWYWT+V3l+ymUJBM9QfAu4GTgYuAXwB/A1QRfG8/DWBmJwM/BD4TTtsM/MzMCsIV5E+A7wGzgR+F70v42tOA24A/AyqBbwGbzKwwhfoOAX8CzAIuAD5hZpeG77skrPcbYU1rgWfC130FWAf8TljTXwPDKS6TS4B7ws/8ATAE/AUwB3gbcC7wybCGMuB+4JfAQmA58IC77wceAi5Let8PAne6+0CKdUgWUyhIpvqGux9w933A/wBPuPvT7t4L3AucFs73x8B/ufuWcKX2FaCYYKV7JhAH/tndB9z9HuDJpM+4GviWuz/h7kPufjvQF75uQu7+kLs/7+7D7v4cQTC9I5z8fuB+d/9h+LkH3f0ZM8sDPgJc6+77ws981N37Ulwmj7n7T8LP7HH3re7+uLsPuvseglAbqeFCYL+7f9Xde929092fCKfdDlwJYGYx4AqC4BRRKEjGOpA03DPG89JweCFQNzLB3YeBemBROG2fH97rY13S8BLgs+HhlzYzawMWh6+bkJm91cweDA+7tAMfJ9hiJ3yPl8d42RyCw1djTUtF/agaTjazn5vZ/vCQ0v9NoQaAnwKrzWwZwd5Yu7v/9jhrkiyjUJDprpFg5Q6AmRnBCnEf0AQsCseNOCFpuB74O3eflfRT4u4/TOFz7wA2AYvdvRy4GRj5nHrgpDFe8xrQO860Q0BJ0u8RIzj0lGx0l8b/BuwAVrj7TILDa8k1nDhW4eHe1t0EewsfRHsJkkShINPd3cAFZnZu2FD6WYJDQI8CjwGDwKfNLG5m7wM2JL3234GPh1v9ZmYzwgbkshQ+twxocfdeM9tAcMhoxA+Ad5nZZWaWb2aVZrY23Iu5DfiamS00s5iZvS1sw3gJKAo/Pw58ETha20YZ0AF0mdkpwCeSpv0cWGBmnzGzQjMrM7O3Jk3/LnAVcDEKBUmiUJBpzd1fJNji/QbBlvhFwEXu3u/u/cD7CFZ+LQTtDz9Oem0N8DHgX4FWYFc4byo+CdxoZp3A9QThNPK+e4HzCQKqhaCR+S3h5M8BzxO0bbQAXwby3L09fM9bCfZyDgGHnY00hs8RhFEnQcDdlVRDJ8GhoYuA/cBO4J1J039D0MD9lLsnH1KTHGe6yY5IbjKzXwN3uPut6a5FModCQSQHmdkZwBaCNpHOdNcjmUOHj0RyjJndTnANw2cUCDKa9hRERCRBewoiIpIQWadaZnYbwVWVr7r7m8aYbsC/EJyl0Q1c5e5PHe1958yZ40uXLp3kakVEstvWrVtfc/fR174cIcqeFr9DcKrfd8eZfh6wIvx5K8GFOG8dZ96EpUuXUlNTM0kliojkBjNL6dTjyA4fuft/E5yHPZ5LgO964HFglpktiKoeERE5unS2KSzi8L5cGsJxIiKSJtOiodnMrjazGjOraW5uTnc5IiJZK513b9pH0HHZiOpw3BHc/RbgFoD169cfcQ7twMAADQ0N9Pb2RlFnxigqKqK6upp4XPdCEZFopDMUNgHXmNmdBA3M7e7edDxv1NDQQFlZGUuXLuXwDjGzh7tz8OBBGhoaWLZsWbrLEZEsFeUpqT8EzgHmhLcZ/BLBDU9w95sJ7pB1PkEnZN3Ah4/3s3p7e7M6EADMjMrKSnT4TESiFFkouPsVR5nuwKcm6/OyORBG5MLvKCLplc7DRyKSxQaHhmlq76WhtYf61m4OtPdSVpTPnLJC5pQWUhU+zizK1wZPBlEoTIK2tjbuuOMOPvnJTx7T684//3zuuOMOZs2aFVFlItEZHnZe6+qjvrWb+pYe6lu6qW/tToRAU1svg8NH71utID+PqtJC5pQWJIIiOTSCxwIqSwspzM8jHssjljd1ITI87AwMDzM07AwMOYND4fBwMDw47AwOOQPh+MHh4XC+YHjkcdhh2ZwZrJhbSn4sc0/8VChMgra2Nr75zW8eEQqDg4Pk54+/iDdv3hx1aSLjGhgapndgiJ6BIfoGXh/uPWw4mNYzMMSh/kEa23qCAGjtZl9rD32Dw4e9Z1VZIYsrijn9hAqq31LM4ooSFs8uYXFFCfPKC+nqHeS1rn5e6+qjubMv8dgcPu5r6+XZhnYOdvUxUZ6YQX6ekZ+XR37MguFYHvHwMXg+anpeHkM+akUerrSDFf7I+Nenj6zMJ1NRPI9VC2ayZlE5b1pUzprqWZxUNSNjgkKhMAmuu+46Xn75ZdauXUs8HqeoqIiKigp27NjBSy+9xKWXXkp9fT29vb1ce+21XH311cDrXXZ0dXVx3nnncfbZZ/Poo4+yaNEifvrTn1JcXJzm3+zYDAwNc6Cjl/3tvTS1Jz129NDU3kt7zwDzZxZRXZG0sphdTHVFCVWlheRNwtbf0LCzv6M32Gpt6aa+tYeG1m4aWno40NlLPJZHUTyP4niMoniMwvwYxQUxivLzKIq/PlwYjyXmScxfEKOsMJ/SonxKC/MpK4wzozA2af/Mw8NOR+8Ard0DtHb30x4+tnYP0NbdT0fPAP1DI1uer2+ZDoQrr8SKLZz++lZqsKIbGHL6BoOVfs/AEEPHsbYrL46zeHYxK+eV8a5V81hcUUz17JLgsaKEonhswtcXlsaoLC1kJRPf8XRo2Gnt7k8Ex2tdfRzs6qdv8PUt7+TfK3kLffzlMEw8L4/8wnziMSOWFCSxvDzisaQgGZkWzjeyd5KfNBw/LHSODKfYqPdwh12vdvH8vnaeb2jnnq0N3P5Y0PNEUTyPUxeW8+ZF4U91OSdVlU7pHtGIadd19vr1631030fbt29n1apVAPzvn22jtrFjUj9z9cKZfOmiU8edvmfPHi688EJeeOEFHnroIS644AJeeOGFxKmjLS0tzJ49m56eHs444wwefvhhKisrDwuF5cuXU1NTw9q1a7nsssu4+OKLufLKK4/4rOTfdaq4O119g7QeGqCpvYf9Hckr/Z7Eyr+5q4/RX6eSghgLyotYUF5MeXGcpvYe6lt7aO7sO2y+gvy8RFhUVxQnti5HQqOiJI6Z4e40d/YlVvbByr+HhrbgsbGt57BDFmYwf2ZRuKVaxNDwMD394dbw4BA9/UP0DR6+Zdw7cPjW79EUx2OUFuUfFhil4fDMonhiuCg/j87ewcRKvq0nWOm3jYRAz8ARyy/59ygrzKcwHktsBcfz8o5Y8cRHVk4jW8vJK7SYBSGXH6O4IC98jFEYD4IwCMRYGI55FCaGg+klBfkUF0y80pfUDQ07r7w2EhIdPL+vjW2NHXT3DwHB9+rUhTN5c3UQFGuqy1k25/iDwsy2uvv6o82nPYUIbNiw4bBrCb7+9a9z7733AlBfX8/OnTuprKw87DXLli1j7dq1AKxbt449e/ZEUlvvwBBt3QO09fTTeujIlVNb0pZpsLIaoL2nn4GhI9dWZUX5LCgvYn55MafMn8mCWUWJ58FjEWWFYzci9g4MJY49NyRt0de39PBsQxtt3QOHzT+jINjCPNDRe8QhizmlhVRXFPOWxbO4cM0CFs8uSQTMwlnFFOQf25a8uyeCYmSrundgiO7+IQ71DdLVN0hX7yCd4WNX3wBdfYN09r4+be+h7tef9w0etlVeWphPeXGcihlxKkoKqK4oYVZxnIqSOLNKCphVEoyfFT6vKIkzsyg+KXtSkjliecbyuWUsn1vGe08Lxg0NO7ubg6B4rqGdF/a1c+dv6/n2wB4AvnjBKj769hMjrSvrQmGiLfqpMmPGjMTwQw89xP33389jjz1GSUkJ55xzzphXXhcWFiaGY7EYPT09k1bPC/vaue2RV7hv234OhVshYynMz0taGcVZPrc0aSUVrKgWlBczP1zhlxYe/9enKB5j+dxSls8tHXN6Z+9AEBphYNS3dHPwUD/zZxYm9iKqw0MWk731ahZuUR/lUEiq3D0RLqWF+cccUpI7YnnGinllrJhXxvtOrwaCoHi5uYvnG9o57YToT0rJulBIh7KyMjo7x76rYXt7OxUVFZSUlLBjxw4ef/zxKalpaNjZUnuA237zCr99pYWSghgXrVnICZUlwUq/uCCxZVoxI3ieSYcGyorirFoQZ9WCmeku5Q0zM4oLYhm1fGX6iOUZJ88r4+R5E7fDTBaFwiSorKzkrLPO4k1vehPFxcXMmzcvMW3jxo3cfPPNrFq1ipUrV3LmmWdGWktn7wB31zTwnUdfob6lh0WzivniBav4o/WLKS9Wn0kiMrGsa2jOduP9rnsPdvPtR1/hRzUNdPUNcsbSCj5y1jLevXpexpzqJiLpo4bmHODuPPFKC7c98gpbth8gZsaFaxbwkbOXsaZaF8SJyLFTKExDfYND/PzZJm77zStsa+ygoiTOp85ZzgfftoR5M4vSXZ6ITGNZEwrunvX9p/QPDtHRM8BZ//Agr3X1sWJuKX//vjdz6dpFasQUkUmRFaFQVFTEwYMHqayszNpg6OjpZ+feJp7b382bFs3kT89extnL52Tt7ysi6ZEVoVBdXU1DQ0PW3mvA3dnf0cf+riHecdopfGyB2gtEJBpZEQrxeDyr70Z215N7+fxPXuFbH1zHyQoEEYmQzlXMcL0DQ/zz/TtZu3gW71k97+gvEBF5AxQKGe77j9fR1N7L5zeeovYDEYmcQiGDdfQOcNODu/jdk6t420mVR3+BiMgbpFDIYLf+925auwf4699fme5SRCRHKBQyVHNnH7c+8goXrFnAmxaVp7scEckRCoUMddODu+gbHOaz7z453aWISA5RKGSg+pZufvBEHZetX8yJVWPfb0BEJAoKhQz0T1teIs+Ma89dke5SRCTHKBQyzI79Hdz7zD6uOmsp88vVuZ2ITC2FQob5yn0vUlqYzyfecVK6SxGRHKRQyCA1e1q4f/urfPwdJzGrpCDd5YhIDlIoZAh358u/3EFVWSEfPmtpussRkRwVaSiY2UYze9HMdpnZdWNMX2JmD5jZc2b2kJlVR1lPJnvoxWae3NPKp89dQUlBVvRTKCLTUGShYGYx4CbgPGA1cIWZrR4121eA77r7GuBG4O+jqieTDQ8HewlLKku4/IzF6S5HRHJYlHsKG4Bd7r7b3fuBO4FLRs2zGvh1OPzgGNNzws+ea2TH/k7+8t0nE4/piJ6IpE+Ua6BFQH3S84ZwXLJngfeFw+8FyszsiJ7fzOxqM6sxs5psu5FO/+AwX/3VS6xaMJOL1ixMdzkikuPSvVn6OeAdZvY08A5gHzA0eiZ3v8Xd17v7+qqqqqmuMVJ3PbmXvS3d/PXGleTlqWtsEUmvKFs09wHJB8irw3EJ7t5IuKdgZqXAH7h7W4Q1ZZTu/kH+5YFdbFg2m3NOzq6wE5HpKco9hSeBFWa2zMwKgMuBTckzmNkcMxup4QvAbRHWk3G+/Zs9vNbVx+c3rtQNdEQkI0QWCu4+CFwD3AdsB+52921mdqOZXRzOdg7wopm9BMwD/i6qejJN66F+bn7oZd61ah7rlsxOdzkiIkC0h49w983A5lHjrk8avge4J8oaMtXND79MV/8gf6Ub6IhIBkl3Q3NOamrv4TuP7uG9py1i5fyydJcjIpKgUEiDrz+wk2F3/uJduoGOiGQWhcIU293cxd01DXzgrUtYPLsk3eWIiBxGoTDFvrrlJQrz87jm95anuxQRkSMoFKbQ8w3t/NdzTXz07Scyp7Qw3eWIiBxBoTCF/vG+HVSUxPnY25eluxQRkTEpFKbIE7sP8j87X+NT71xOWVE83eWIiIxJoTBFflV7gML8PK48c0m6SxERGZdCYYrU1LXylsWzKIrH0l2KiMi4FApToHdgiG372lm3pCLdpYiITEihMAWerW9jcNhZr1AQkQynUJgCW/e2AnD6CQoFEclsCoUpsHVPKydVzaBiRkG6SxERmZBCIWLDw87Wva2sV/fYIjINKBQitvu1Q7R1D6iRWUSmBYVCxLbWtQCwbqlCQUQyn0IhYlvrWqkoiXPinBnpLkVE5KgUChGrqWtl3ZIK3YNZRKYFhUKEWg71s7v5kO7BLCLThkIhQk/VBdcnqJFZRKYLhUKEaupaiceMNdXl6S5FRCQlCoUIPVXXyqkLy9UJnohMGwqFiPQPDvNsQ5v6OxKRaUWhEJFtje30DQ6zXtcniMg0olCIyNawkfl07SmIyDSiUIhIzZ5WTphdwtyyonSXIiKSMoVCBNyDTvB0KqqITDcKhQjUt/TQ3NmnUBCRaSfSUDCzjWb2opntMrPrxph+gpk9aGZPm9lzZnZ+lPVMla17w07wFAoiMs1EFgpmFgNuAs4DVgNXmNnqUbN9Ebjb3U8DLge+GVU9U6lmTytlhfmcPK8s3aWIiByTKPcUNgC73H23u/cDdwKXjJrHgZnhcDnQGGE9U2ZrXSunLakglqdO8ERkeokyFBYB9UnPG8JxyW4ArjSzBmAz8OdjvZGZXW1mNWZW09zcHEWtk6ajd4AXD3SyTvdjFpFpKN0NzVcA33H3auB84HtmdkRN7n6Lu6939/VVVVVTXuSxeHpvG+7oojURmZaiDIV9wOKk59XhuGR/CtwN4O6PAUXAnAhritzWulbyDN6yeFa6SxEROWZRhsKTwAozW2ZmBQQNyZtGzbMXOBfAzFYRhEJmHx86iq11LaxaMJPSwvx0lyIicswiCwV3HwSuAe4DthOcZbTNzG40s4vD2T4LfMzMngV+CFzl7h5VTVEbHBrm6b3qBE9Epq9IN2fdfTNBA3LyuOuThmuBs6KsYSrt2N9Jd/+Q+jsSkWkr3Q3NWWWkE7z1S3X7TRGZnhQKk2hrXSvzZxaxsFyd4InI9KRQmERb61pZt7QCM120JiLTk0JhkjS197CvrUcXrYnItKZQmCSvtycoFERk+lIoTJKaPa0Ux2OsWjDz6DOLiGSolELBzH5sZheM1QWFBJ7a28pbFpcTj2kRicj0leoa7JvA+4GdZvYPZrYywpqmne7+QbY1drB+iU5FFZHpLaVQcPf73f0DwOnAHuB+M3vUzD5sZvEoC5wOnqlvY2jYdVMdEZn2Uj7WYWaVwFXAR4GngX8hCIktkVQ2jTwVNjKfrjOPRGSaS6mbCzO7F1gJfA+4yN2bwkl3mVlNVMVNFzV1rZw8r5TykpzfaRKRaS7Vvo++7u4PjjXB3ddPYj3TzvCw81RdKxesWZDuUkRE3rBUDx+tNrPEDQLMrMLMPhlRTdPKruYuOnoHWadGZhHJAqmGwsfcvW3kibu3Ah+LpqTppWZP0J6gRmYRyQaphkLMkjr0MbMYUBBNSdPL1rpWKmcUsLSyJN2liIi8Yam2KfySoFH5W+HzPwvH5bytdS2cvkSd4IlIdkg1FD5PEASfCJ9vAW6NpKJp5LWuPvYc7OaKDSekuxQRkUmRUii4+zDwb+GPhNQJnohkm1SvU1gB/D2wGkjcQcbdT4yormlha10rBbE8Tl1Ynu5SREQmRaoNzd8m2EsYBN4JfBf4flRFTRdb61p5c3U5RfFYuksREZkUqYZCsbs/AJi717n7DcAF0ZWV+XoHhni+oV2noopIVkm1obkv7DZ7p5ldA+wDSqMrK/Nta2ynf2hYoSAiWSXVPYVrgRLg08A64ErgQ1EVNR3oojURyUZH3VMIL1T7Y3f/HNAFfDjyqqaBmrpWllaWMKe0MN2liIhMmqPuKbj7EHD2FNQybbgHneCpvyMRyTaptik8bWabgB8Bh0ZGuvuPI6kqw+052M3BQ/06dCQiWSfVUCgCDgK/lzTOgZwMBV20JiLZKtUrmo+rHcHMNhLcoS0G3Oru/zBq+j8RXPcAQUP2XHefRYbbWtfCzKJ8llfl9AlYIpKFUr2i+dsEewaHcfePTPCaGHAT8G6gAXjSzDa5e23S6/8iaf4/B05LvfT0qdnTyulLKsjLUyd4IpJdUj189POk4SLgvUDjUV6zAdjl7rsBzOxO4BKgdpz5rwC+lGI9adPePcDOV7u4ZO3CdJciIjLpUj189J/Jz83sh8AjR3nZIqA+6XkD8NaxZjSzJcAy4NfjTL8auBrghBPS2yPpU3uD9oTT1cgsIlko1YvXRlsBzJ3EOi4H7glPfz2Cu9/i7uvdfX1VVdUkfuyx21rXSizPWLs445s+RESOWaptCp0c3qawn+AeCxPZByxOel4djhvL5cCnUqkl3WrqWli9YCYlBakeeRMRmT5SPXxUdhzv/SSwwsyWEYTB5cD7R89kZqcAFcBjx/EZU2pgaJhn6tu4/AzdVEdEslNKh4/M7L1mVp70fJaZXTrRa9x9ELgGuA/YDtzt7tvM7EYzuzhp1suBO939iLObMs32pg56B4Z1fYKIZK1Uj4F8yd3vHXni7m1m9iXgJxO9yN03A5tHjbt+1PMbUqwh7dQJnohku1QbmseaL+cOqm/d28qiWcUsKC9OdykiIpFINRRqzOxrZnZS+PM1YGuUhWUad2dreNGaiEi2SjUU/hzoB+4C7gR6mSZnC02WfW097O/oZb1CQUSyWKpnHx0Crou4low20gme2hNEJJulevbRFjOblfS8wszui66szPN8QzuF+XmcMv94zs4VEZkeUj18NMfd20aeuHsrk3tFc8arberglPll5MeO9yJwEZHMl+oabtjMEldsmdlSxug1NVu5O7VNHaxeODPdpYiIRCrV00r/FnjEzB4GDHg7YQd1uaCxvZe27gFWL1AoiEh2S7Wh+Zdmtp4gCJ4muGitJ8rCMkltYwcAqxeWH2VOEZHpLdUO8T4KXEvQqd0zwJkEfRX93kSvyxa1jR2YoUZmEcl6qbYpXAucAdS5+zsJ7pDWNvFLskdtUzvLKmcwozDnLuIWkRyTaij0unsvgJkVuvsOYGV0ZWWWbY1qZBaR3JBqKDSE1yn8BNhiZj8F6qIrK3O09wzQ0NqjUBCRnJBqQ/N7w8EbzOxBoBz4ZWRVZZDtTWEjs848EpEccMwHyd394SgKyVTbEmceKRREJPvp8tyjqG3soKqskLllRekuRUQkcgqFo6ht6tChIxHJGQqFCfQPDrPr1U4dOhKRnKFQmMBLBzoZGHJOVSiISI5QKEygVmceiUiOUShMoLaxg5KCGEsqZ6S7FBGRKaFQmEBtY3APhViepbsUEZEpoVAYx/BwcA+FU9UzqojkEIXCOBpae+jqG9SZRyKSUxQK46htagfUyCwiuUWhMI5tjR3E8oyVuoeCiOQQhcI4ahs7OKlqBkXxWLpLERGZMgqFcah7CxHJRZGGgpltNLMXzWyXmV03zjyXmVmtmW0zszuirCdVLYf6aWrvVSOziOScyO4vaWYx4Cbg3UAD8KSZbXL32qR5VgBfAM5y91YzmxtVPceiNuwuW6ejikiuiXJPYQOwy913u3s/cCdwyah5Pgbc5O6tAO7+aoT1pGzkzKNVOnwkIjkmylBYBNQnPW8IxyU7GTjZzH5jZo+b2cax3sjMrjazGjOraW5ujqjc19U2drCgvIjZMwoi/ywRkUyS7obmfGAFcA5wBfDv4b2gD+Put7j7endfX1VVFXlR2xo71DOqiOSkKENhH7A46Xl1OC5ZA7DJ3Qfc/RXgJYKQSJvegSFebu7SmUcikpOiDIUngRVmtszMCoDLgU2j5vkJwV4CZjaH4HDS7ghrOqoX93cy7Lons4jkpshCwd0HgWuA+4DtwN3uvs3MbjSzi8PZ7gMOmlkt8CDwV+5+MKqaUrFNZx6JSA6L7JRUAHffDGweNe76pGEH/jL8yQi1Te2UFeZTXVGc7lJERKZcuhuaM05tYwerFs7ETPdQEJHco1BIMjTs7NjfqUZmEclZCoUkew4eort/SKejikjOUigkGeneQmceiUiuUigkqW3qIB4zVszVPRREJDcpFJJsa+xgxdwyCvK1WEQkN2ntl6S2sUOHjkQkpykUQq929vJaV5/OPBKRnKZQCKmRWUREoZCwTaEgIqJQGFHb1MHi2cXMLIqnuxQRkbRRKIS2N3aoPUFEcp5CATjUN8grBw+pZ1QRyXkKBWDH/g7c0Z6CiOQ8hQI680hEZIRCgaCReVZJnAXlRekuRUQkrRQKBKejnqp7KIiIKBQGh4Z1DwURkVDOh8Lu1w7RPzis9gQRERQKiUZmnY4qIqJQYFtjOwX5eZw4Z0a6SxERSbucD4Xapg5OmV9GfiznF4WISG6HgrsH91BQI7OICJDjodDU3ktr9wCnqpFZRATI8VDQlcwiIofL7VBo6sAMTpmvUBARgVwPhcYOllXOYEZhfrpLERHJCJGGgpltNLMXzWyXmV03xvSrzKzZzJ4Jfz4aZT2jbWtqZ5UOHYmIJEQWCmYWA24CzgNWA1eY2eoxZr3L3deGP7dGVc9o7T0D1Lf06MwjEZEkUe4pbAB2uftud+8H7gQuifDzjsmOppErmRUKIiIjogyFRUB90vOGcNxof2Bmz5nZPWa2eKw3MrOrzazGzGqam5snpbhtOvNIROQI6W5o/hmw1N3XAFuA28eayd1vcff17r6+qqpqUj64tqmDOaWFzC3TPRQGib9mAAAIoElEQVREREZEGQr7gOQt/+pwXIK7H3T3vvDprcC6COs5TG1jh/YSRERGiTIUngRWmNkyMysALgc2Jc9gZguSnl4MbI+wnoT+wWF2vtqp9gQRkVEiO0Hf3QfN7BrgPiAG3Obu28zsRqDG3TcBnzazi4FBoAW4Kqp6ku18tZOBIdeZRyIio0R61Za7bwY2jxp3fdLwF4AvRFnDWNS9hYjI2NLd0JwWtU0dlBTEWFqpeyiIiCTLyVDY1hjcQyGWZ+kuRUQko+RcKLg723XmkYjImHIuFBpae+jsG2T1At2TWURktJwLhZErmXU6qojIkXIuFGob28kzWDm/LN2liIhknNwLhaYOTqoqpSgeS3cpIiIZJ/dCobFDh45ERMaRU6HQeqifxvZenXkkIjKOnAqF2vAeCjrzSERkbLkVCureQkRkQrkVCk0dLCgvYvaMgnSXIiKSkXIqFLY1tqtnVBGRCeRMKPQODPFy8yEdOhIRmUDOhMJLBzoZGnadjioiMoGcCYWR7i105pGIyPhyJhQqZxTw7tXzqK4oTncpIiIZK9I7r2WS95w6n/ecOj/dZYiIZLSc2VMQEZGjUyiIiEiCQkFERBIUCiIikqBQEBGRBIWCiIgkKBRERCRBoSAiIgnm7umu4ZiYWTNQd5wvnwO8NonlTDbV98aovjcu02tUfcdvibtXHW2maRcKb4SZ1bj7+nTXMR7V98aovjcu02tUfdHT4SMREUlQKIiISEKuhcIt6S7gKFTfG6P63rhMr1H1RSyn2hRERGRiubanICIiE1AoiIhIQlaGgpltNLMXzWyXmV03xvRCM7srnP6EmS2dwtoWm9mDZlZrZtvM7Nox5jnHzNrN7Jnw5/qpqi/8/D1m9nz42TVjTDcz+3q4/J4zs9OnsLaVScvlGTPrMLPPjJpnypefmd1mZq+a2QtJ42ab2RYz2xk+Vozz2g+F8+w0sw9NUW3/z8x2hH+/e81s1jivnfC7EHGNN5jZvqS/4/njvHbC//cI67srqbY9ZvbMOK+dkmU4adw9q36AGPAycCJQADwLrB41zyeBm8Phy4G7prC+BcDp4XAZ8NIY9Z0D/DyNy3APMGeC6ecDvwAMOBN4Io1/6/0EF+WkdfkBvwucDryQNO4fgevC4euAL4/xutnA7vCxIhyumILa3gPkh8NfHqu2VL4LEdd4A/C5FL4DE/6/R1XfqOlfBa5P5zKcrJ9s3FPYAOxy993u3g/cCVwyap5LgNvD4XuAc83MpqI4d29y96fC4U5gO7BoKj57El0CfNcDjwOzzGxBGuo4F3jZ3Y/3CvdJ4+7/DbSMGp38PbsduHSMl/4+sMXdW9y9FdgCbIy6Nnf/lbsPhk8fB6on8zOP1TjLLxWp/L+/YRPVF647LgN+ONmfmw7ZGAqLgPqk5w0cudJNzBP+Y7QDlVNSXZLwsNVpwBNjTH6bmT1rZr8ws1OntDBw4FdmttXMrh5jeirLeCpczvj/iOlcfiPmuXtTOLwfmDfGPJmwLD9CsOc3lqN9F6J2TXiI67ZxDr9lwvJ7O3DA3XeOMz3dy/CYZGMoTAtmVgr8J/AZd+8YNfkpgkMibwG+Afxkiss7291PB84DPmVmvzvFn39UZlYAXAz8aIzJ6V5+R/DgOELGnf9tZn8LDAI/GGeWdH4X/g04CVgLNBEcoslEVzDxXkLG/z8ly8ZQ2AcsTnpeHY4bcx4zywfKgYNTUl3wmXGCQPiBu/949HR373D3rnB4MxA3szlTVZ+77wsfXwXuJdhFT5bKMo7aecBT7n5g9IR0L78kB0YOq4WPr44xT9qWpZldBVwIfCAMrSOk8F2IjLsfcPchdx8G/n2cz07rdzFcf7wPuGu8edK5DI9HNobCk8AKM1sWbk1eDmwaNc8mYOQsjz8Efj3eP8VkC48//gew3d2/Ns4880faOMxsA8HfaUpCy8xmmFnZyDBBg+QLo2bbBPxJeBbSmUB70mGSqTLu1lk6l98oyd+zDwE/HWOe+4D3mFlFeHjkPeG4SJnZRuCvgYvdvXuceVL5LkRZY3I71XvH+exU/t+j9C5gh7s3jDUx3cvwuKS7pTuKH4KzY14iOCvhb8NxNxL8AwAUERx22AX8FjhxCms7m+AwwnPAM+HP+cDHgY+H81wDbCM4k+Jx4HemsL4Tw899NqxhZPkl12fATeHyfR5YP8V/3xkEK/nypHFpXX4EAdUEDBAc1/5TgnaqB4CdwP3A7HDe9cCtSa/9SPhd3AV8eIpq20VwLH7kOzhyNt5CYPNE34UpXH7fC79fzxGs6BeMrjF8fsT/+1TUF47/zsj3LmnetCzDyfpRNxciIpKQjYePRETkOCkUREQkQaEgIiIJCgUREUlQKIiISIJCQWQKhT24/jzddYiMR6EgIiIJCgWRMZjZlWb227AP/G+ZWczMuszsnyy4D8YDZlYVzrvWzB5PujdBRTh+uZndH3bM95SZnRS+famZ3RPez+AHU9VDr0gqFAoio5jZKuCPgbPcfS0wBHyA4ErqGnc/FXgY+FL4ku8Cn3f3NQRX4I6M/wFwkwcd8/0OwRWxEPSM+xlgNcEVr2dF/kuJpCg/3QWIZKBzgXXAk+FGfDFBZ3bDvN7x2feBH5tZOTDL3R8Ox98O/Cjs72aRu98L4O69AOH7/dbDvnLCu3UtBR6J/tcSOTqFgsiRDLjd3b9w2Eiz/zVqvuPtI6YvaXgI/R9KBtHhI5EjPQD8oZnNhcS9lpcQ/L/8YTjP+4FH3L0daDWzt4fjPwg87MFd9RrM7NLwPQrNrGRKfwuR46AtFJFR3L3WzL5IcLesPIKeMT8FHAI2hNNeJWh3gKBb7JvDlf5u4MPh+A8C3zKzG8P3+KMp/DVEjot6SRVJkZl1uXtpuusQiZIOH4mISIL2FEREJEF7CiIikqBQEBGRBIWCiIgkKBRERCRBoSAiIgn/H52YbXVtUfNvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt4XXWd7/H3d19ybbKTpmkoSW9cbaGhLbUoF4dHiwOooKgIikfUIzozzOAZxzN4dByP5zaOc2bGC47CyKMyDooCiloOWhVGRoq0XEovUEql07Sl96Rp7jv7e/5YK2GTJmmSdmVl73xez5Nnr73Wb+/93Ss7+5O1fmv9lrk7IiIiAIm4CxARkalDoSAiIoMUCiIiMkihICIigxQKIiIySKEgIiKDFAoiY2Rm3zKz/znGti+Z2aoTfR6RyaZQEBGRQQoFEREZpFCQohLutvmkmW0wsw4z+6aZNZjZg2bWbmZrzKw2r/1VZrbJzFrN7GEzW5S3bJmZPRk+7vtA2ZDXequZPR0+9rdm1jzBmj9iZtvM7JCZPWBmp4bzzcz+wcz2mdkRM3vWzM4Nl11pZpvD2naZ2V9MaIWJDKFQkGL0TuAy4CzgbcCDwH8D6gk+838GYGZnAXcDHw+XrQZ+YmYlZlYC/Ai4C5gJ/CB8XsLHLgPuBD4K1AHfAB4ws9LxFGpmbwT+D3AtMAfYAXwvXPxm4A3h+8iEbQ6Gy74JfNTdq4BzgV+N53VFRqJQkGL0FXff6+67gN8Aj7v7U+7eDdwPLAvbvQf4mbv/wt37gL8DyoELgdcBaeAf3b3P3X8IPJH3GjcB33D3x929392/DfSEjxuP9wF3uvuT7t4DfAp4vZktAPqAKuA1gLn7FnffEz6uD1hsZtXuftjdnxzn64oMS6EgxWhv3nTXMPdnhNOnEvxnDoC754CdQGO4bJe/esTIHXnT84FPhLuOWs2sFZgbPm48htZwlGBroNHdfwV8FbgN2Gdmt5tZddj0ncCVwA4ze8TMXj/O1xUZlkJBprPdBF/uQLAPn+CLfRewB2gM5w2Ylze9E/hf7l6T91Ph7nefYA2VBLujdgG4+5fd/XxgMcFupE+G859w96uB2QS7ue4Z5+uKDEuhINPZPcBbzOxNZpYGPkGwC+i3wGNAFvgzM0ub2TXAyrzH3gF8zMwuCDuEK83sLWZWNc4a7gY+aGZLw/6I/02wu+slM3tt+PxpoAPoBnJhn8f7zCwT7vY6AuROYD2IDFIoyLTl7s8DNwBfAQ4QdEq/zd173b0XuAa4EThE0P9wX95j1wEfIdi9cxjYFrYdbw1rgL8C7iXYOjkduC5cXE0QPocJdjEdBL4YLns/8JKZHQE+RtA3IXLCTBfZERGRAdpSEBGRQQoFEREZpFAQEZFBCgURERmUiruA8Zo1a5YvWLAg7jJERArK+vXrD7h7/fHaFVwoLFiwgHXr1sVdhohIQTGzHcdvpd1HIiKSR6EgIiKDFAoiIjKo4PoUhtPX10dLSwvd3d1xlxKpsrIympqaSKfTcZciIkWqKEKhpaWFqqoqFixYwKsHtSwe7s7BgwdpaWlh4cKFcZcjIkWqKHYfdXd3U1dXV7SBAGBm1NXVFf3WkIjEqyhCASjqQBgwHd6jiMSraELheDp6suxp60KjwoqIjGzahEJXXz/723voyZ78a5G0trbyta99bdyPu/LKK2ltbT3p9YiITNS0CYXqsuCInSPdfSf9uUcKhWw2O+rjVq9eTU1NzUmvR0Rkoori6KOxKEklKE8nae/KMnu8F0w8jltvvZUXX3yRpUuXkk6nKSsro7a2lueee46tW7fy9re/nZ07d9Ld3c0tt9zCTTfdBLwyZMfRo0e54ooruPjii/ntb39LY2MjP/7xjykvLz+5hYqIHEfRhcJ//8kmNu8+Muyyvv4cvdkcFaUpxtNlu/jUav76beeMuPxv/uZv2LhxI08//TQPP/wwb3nLW9i4cePgoaN33nknM2fOpKuri9e+9rW8853vpK6u7lXP8cILL3D33Xdzxx13cO2113Lvvfdyww03jKNKEZETV3ShMJpkIoiC/pyTSkR3JM/KlStfdS7Bl7/8Ze6//34Adu7cyQsvvHBMKCxcuJClS5cCcP755/PSSy9FVp+IyEiKLhRG+4/e3Xnu5XYqSpLMr6uMrIbKylee++GHH2bNmjU89thjVFRUcOmllw57rkFpaengdDKZpKurK7L6RERGMm06miE4zr+6LEV7d5Zc7uQdmlpVVUV7e/uwy9ra2qitraWiooLnnnuOtWvXnrTXFRE52YpuS+F4qsvTHOzo5WhPlurykzOGUF1dHRdddBHnnnsu5eXlNDQ0DC67/PLL+frXv86iRYs4++yzed3rXndSXlNEJAoW1clcZnYn8FZgn7ufO8xyA74EXAl0Aje6+5PHe94VK1b40IvsbNmyhUWLFo2prpw7m3cfoaYiTVNtxZgeM5WM572KiAwws/XuvuJ47aLcffQt4PJRll8BnBn+3AT8U4S1DEqYURXuQtLZzSIirxZZKLj7vwGHRmlyNfAdD6wFasxsTlT15KsuS9PXn6Orr38yXk5EpGDE2dHcCOzMu98SzjuGmd1kZuvMbN3+/fuHfbLx/NdfVRacp3Cka/QzjqcabdmISNQK4ugjd7/d3Ve4+4r6+vpjlpeVlXHw4MExf2mmkgkqSlORDHkRlYHrKZSVlcVdiogUsTiPPtoFzM273xTOG7empiZaWloYaStiOO3dWdq6+ug5UEoqURDZOHjlNRGRqMQZCg8AN5vZ94ALgDZ33zORJ0qn0+O+GtnvD3Rw7d89zOfetpgbL9KVzEREIMLdR2Z2N/AYcLaZtZjZh83sY2b2sbDJamA7sA24A/jjqGoZzsJZlZxeX8maLfsm82VFRKa0yLYU3P364yx34E+iev2xWLW4gW/+5vcc6e4bHFpbRGQ6K4yd6RG5bFED2ZzzyPNj74sQESlm0zoUls2rpa6yhF9s3ht3KSIiU8K0DoVkwnjja2bz6+f30dd/8i/TKSJSaKZ1KEDQr9DeneWJ34928rWIyPQw7UPhkjNnUZJK8Ist2oUkIjLtQ6GiJMXFZ8xizZa9GkZCRKa9aR8KAKsWNbDzUBdb9x6NuxQRkVgpFIA3LZoNwBrtQhKRaU6hADRUl3FeU0aHporItKdQCK1a1MDTO1vZ194ddykiIrFRKIQuOye4rvKvNBaSiExjCoXQ2Q1VNNWWaxeSiExrCoWQmbFqUQOPbjtAZ29hXZFNRORkUSjkuWxxAz3ZHI++cCDuUkREYqFQyLNy4UyqylI6NFVEpi2FQp50MsGlZ8/ml1v20Z/T2c0iMv0oFIZYtWg2Bzt6eXpna9yliIhMOoXCEJeePZtUwrQLSUSmJYXCEJnyNBecNpM1OjRVRKYhhcIwVi1q4IV9R3npQEfcpYiITCqFwjBWLQrObtYuJBGZbhQKw5g7s4LXnFKls5tFZNpRKIxg1aIG1u04zOGO3rhLERGZNAqFEaxa3EB/znl4qwbIE5HpQ6EwgubGDPVVpazZrFAQkelDoTCCRMJYtWg2j2zdT0+2P+5yREQmhUJhFKsWNXC0J8vj2w/FXYqIyKRQKIziojNmUZ5O6tBUEZk2FAqjKEsnueTMWazZvBd3DZAnIsVPoXAcqxY3sLutm817jsRdiohI5CINBTO73MyeN7NtZnbrMMvnmdmvzewpM9tgZldGWc9EvPE1szFDJ7KJyLQQWSiYWRK4DbgCWAxcb2aLhzT7DHCPuy8DrgO+FlU9EzVrRinL59WqX0FEpoUotxRWAtvcfbu79wLfA64e0saB6nA6A+yOsJ4JW7WogY27jrCnrSvuUkREIhVlKDQCO/Put4Tz8n0OuMHMWoDVwJ8O90RmdpOZrTOzdfv374+i1lFdtng2AGu26EQ2ESlucXc0Xw98y92bgCuBu8zsmJrc/XZ3X+HuK+rr6ye9yNPrZ7CgrkLXWBCRohdlKOwC5ubdbwrn5fswcA+Auz8GlAGzIqxpQsyMyxY38NiLB+nq1dnNIlK8ogyFJ4AzzWyhmZUQdCQ/MKTNfwBvAjCzRQShMPn7h8bggoV19Pbn2LS7Le5SREQiE1kouHsWuBl4CNhCcJTRJjP7vJldFTb7BPARM3sGuBu40afoWWJLmjIAbGhRKIhI8UpF+eTuvpqgAzl/3mfzpjcDF0VZw8nSUF1GQ3Upz+5SKIhI8Yq7o7mgNDfVsKGlNe4yREQio1AYh+bGDNsPdNDe3Rd3KSIikVAojMOSpgzusHGXxkESkeKkUBiH5qYaAJ7dpV1IIlKcFArjMLOyhKbach2BJCJFS6EwTs1NGR2BJCJFS6EwTksaa9hxsJPWzt64SxEROekUCuPUHJ7Epq0FESlGCoVxOrdRZzaLSPFSKIxTpjzNwlmVPKtQEJEipFCYgCWNGZ3ZLCJFSaEwAc1NGXa3dbO/vSfuUkRETiqFwgQsCfsVNqqzWUSKjEJhAs5tzGCmzmYRKT4KhQmoLE1xRv0M9SuISNFRKEzQkqYMG3a1MUWvCSQiMiEKhQlqbsywv72HvUfU2SwixUOhMEHNc4MRU7ULSUSKiUJhghbPqSaZMA13ISJFRaEwQWXpJGc1VPGMjkASkSKiUDgBzY0Znm1pVWeziBQNhcIJaJ6b4XBnHy2Hu+IuRUTkpFAonIDmxoHLc2oXkogUB4XCCTjrlBmUJBM8oyOQRKRIKBROQGkqyWvmVGkYbREpGgqFE7SkMbhmcy6nzmYRKXwKhRN0XlMN7d1ZdhzqjLsUEZETplA4QUuaBi7PqX4FESl8CoUTdObsGZSmEhpGW0SKgkLhBKWSCc45tVqdzSJSFCINBTO73MyeN7NtZnbrCG2uNbPNZrbJzP41ynqi0txUw8bdbfSrs1lEClxkoWBmSeA24ApgMXC9mS0e0uZM4FPARe5+DvDxqOqJUnNThs7efl7cfzTuUkRETkiUWworgW3uvt3de4HvAVcPafMR4DZ3Pwzg7vsirCcyzYOdzdqFJCKFLcpQaAR25t1vCeflOws4y8z+3czWmtnlwz2Rmd1kZuvMbN3+/fsjKnfiFs6aQWVJkmd1BJKIFLi4O5pTwJnApcD1wB1mVjO0kbvf7u4r3H1FfX39JJd4fMmEcW5jcHlOEZFCFmUo7ALm5t1vCuflawEecPc+d/89sJUgJApOc1OGzbuP0Nefi7sUEZEJizIUngDONLOFZlYCXAc8MKTNjwi2EjCzWQS7k7ZHWFNkljTV0JPNsXVve9yliIhM2JhCwcxuMbNqC3zTzJ40szeP9hh3zwI3Aw8BW4B73H2TmX3ezK4Kmz0EHDSzzcCvgU+6+8GJv534NDcGnc06X0FECllqjO0+5O5fMrM/BGqB9wN3AT8f7UHuvhpYPWTeZ/OmHfjz8Kegza+roLosxYZdbVwXdzEiIhM01t1HFt5eCdzl7pvy5glgZjQ31WhLQUQK2lhDYb2Z/ZwgFB4ysypAPapDLGnK8NzLR+jJ9sddiojIhIw1FD4M3Aq81t07gTTwwciqKlDNjRn6+p3n9qizWUQK01hD4fXA8+7eamY3AJ8BtJ9kiMFhtHW+gogUqLGGwj8BnWZ2HvAJ4EXgO5FVVaAaa8qpqyzRmc0iUrDGGgrZ8Eihq4GvuvttQFV0ZRUmM2NJU0ZjIIlIwRprKLSb2acIDkX9mZklCPoVZIjmxgxb97bT1avOZhEpPGMNhfcAPQTnK7xMMGTFFyOrqoAtaaoh57B5j7YWRKTwjCkUwiD4LpAxs7cC3e6uPoVhaBhtESlkYx3m4lrgd8C7gWuBx83sXVEWVqgaqstoqC5VKIhIQRrrMBefJjhHYR+AmdUDa4AfRlVYIVvSWMMGHYEkIgVorH0KiSFXRTs4jsdOO81NGbYf6KC9uy/uUkRExmWsX+z/z8weMrMbzexG4GcMGehOXtHclMEdNu0+EncpIiLjMtaO5k8CtwPN4c/t7v6XURZWyJZoGG0RKVBj7VPA3e8F7o2wlqJRN6OUxppynlG/gogUmFFDwczaAR9uEcHlEKojqaoINDdleFZjIIlIgRk1FNxdQ1lM0JKmDA9ufJm2zj4yFTr5W0QKg44gish5TTUA2loQkYKiUIjIuacGnc3qVxCRQqJQiEimIs2CugodgSQiBUWhEKElTTXafSQiBUWhEKHzmjLsau3iwNGeuEsRERkThUKEdBKbiBQahUKEzmnMYKZhtEWkcCgUIjSjNMXp9TN4dpeOQBKRwqBQiFizrtksIgVEoRCx5sYM+9p7eLmtO+5SRESOS6EQsSXhmc266I6IFAKFQsQWz6kmmTCdryAiBSHSUDCzy83seTPbZma3jtLunWbmZrYiynriUF6S5MzZM9SvICIFIbJQMLMkcBtwBbAYuN7MFg/Trgq4BXg8qlridl54ZrP7cKOQi4hMHVFuKawEtrn7dnfvBb4HXD1Mu/8BfAEo2p7YJU0ZDnX00nK4K+5SRERGFWUoNAI78+63hPMGmdlyYK67/yzCOmLX3BSe2ax+BRGZ4mLraDazBPD3wCfG0PYmM1tnZuv2798ffXEn2dmnVJFOmvoVRGTKizIUdgFz8+43hfMGVAHnAg+b2UvA64AHhutsdvfb3X2Fu6+or6+PsORolKaSLJpTrTObRWTKizIUngDONLOFZlYCXAc8MLDQ3dvcfZa7L3D3BcBa4Cp3XxdhTbFZ0hic2ZzLqbNZRKauyELB3bPAzcBDwBbgHnffZGafN7Oronrdqer8+bW0d2d5WiexicgUloryyd19NbB6yLzPjtD20ihridtlixsoTSX40VO7WD6vNu5yRESGpTOaJ0lVWZrLFjfwk2d205vNxV2OiMiwFAqT6JrljRzu7OPh5/fFXYqIyLAUCpPokjPrqass4f6ndh2/sYhIDBQKkyidTPC2807ll1v20dbZF3c5IiLHUChMsmuWN9Lbn+Nnz+6JuxQRkWMoFCbZksYMp9dXcv9TLXGXIiJyDIXCJDMzrlnexBMvHWbnoc64yxEReRWFQgyuXnoqgDqcRWTKUSjEoKm2ggsWzuT+p3bpGgsiMqUoFGJyzfJGfn+gg6d3atgLEZk6FAoxuWLJHEpTCe1CEpEpRaEQk+qyNKs07IWITDEKhRhdsywY9uKRrYV34SARKU4KhRi94ayBYS90zoKITA0KhRgNDHuxZss+2ro07IWIxE+hELN3LGukN5tjtYa9EJEpQKEQs+amDKfVV3L/kzoKSUTip1CImZlxzbJGfvfSIQ17ISKxUyhMAVcvbQTgRzpnQURiplCYAubOrGClhr0QkSlAoTBFXLOske0HOnimpS3uUkRkGlMoTBFXLJlDSSrB/U/qnAURiY9CYYrIlKe5bHEDP9mwh75+DXshIvFQKEwh1yxr5FBHL488r2EvRCQeCoUp5JVhL3QUkojEQ6EwhQwMe/GLLXs17IWIxEKhMMUMDHvxoIa9EJEYKBSmmIFhL+7TLiQRiYFCYYoZHPbi9xr2QkQmn0JhChoY9uLHT2trQUQmV6ShYGaXm9nzZrbNzG4dZvmfm9lmM9tgZr80s/lR1lMoBoa9uE/DXojIJIssFMwsCdwGXAEsBq43s8VDmj0FrHD3ZuCHwN9GVU+huWZZI9v3d7BBw16IyCSKckthJbDN3be7ey/wPeDq/Abu/mt3H9hxvhZoirCegjIw7MV9GvZCRCZRlKHQCOzMu98SzhvJh4EHh1tgZjeZ2TozW7d///Q42zdTnuayRRr2QkQm15ToaDazG4AVwBeHW+7ut7v7CndfUV9fP7nFxegdGvZCRCZZlKGwC5ibd78pnPcqZrYK+DRwlbv3RFhPwfmDs+uZqWEvRGQSRRkKTwBnmtlCMysBrgMeyG9gZsuAbxAEwr4IaylI6WSCtzXP0bAXIjJpIgsFd88CNwMPAVuAe9x9k5l93syuCpt9EZgB/MDMnjazB0Z4umnrHcubNOyFiEyaVJRP7u6rgdVD5n02b3pVlK9fDM5rynDarGDYi+tWzou7HBEpclOio1lGZma8Q8NeiMgkUSgUgLcv07AXIjI5FAoFYO7MClYuCIa96M9p2AsRiY5CoUBcf8Fctu/v4H3/vJaX27rjLkdEipRCoUC8fWkjf/fu89jQ0sblX/o3fr7p5bhLEpEipFAoEGbGu85v4qd/ejFNteXcdNd6/upHG+nu64+7NBEpIgqFAnNa/Qzu/aML+cglC7lr7Q6u/uq/s3Vve9xliUiRUCgUoNJUkk+/ZTHf/tBKDnb08LavPMq/rN2hay+IyAlTKBSwPzirngdveQMXnFbHZ360kY/etZ7Wzt64yxKRAqZQKHD1VaV868bX8pm3LOLXz+/jii/9hrXbD8ZdlogUKIVCEUgkjP98yWnc90cXUZZO8t471vL3P3+erK7DICLjpFAoIkuaMvz0Ty/mncub+PKvtvGe29dqaAwRGReFQpGpLE3xxXefx5euW8rWl9u58su/4acbdsddlogUCIVCkbp6aSOrb7mEM2bP4OZ/fYq//OEGOnuzcZclIlNcpENnS7zmzqzgno++nn9cs5WvPfwij247wNJ5NcyfWcG8gZ+6CuZkykkmLO5yRWQKUCgUuXQywSf/8DVcdMYsvvHIdjbtauOhjS+TzRtYL500mmormDuzgnkzy5k/szKcDkJjRqk+JiLThf7ap4kLT5/FhafPAiDbn2NPWzc7D3XyH4c62RHe7jzUyTM7W4+59GddZQlzZ1Zw2qxKls6rYfm8Wl5zShWppPY+ihQbhcI0lEommDsz2DK4cJjlbZ197DzcyY6DQVgEPx08uu0A9z0VXNOhsiTJ0nk1nD+vluXza1k2r5ZMeXpy34iInHQKBTlGpiJNpiLDuY2ZV813d3a3dbPupUM8ueMw63Yc5qu/3kbOwQzOml3F8vm1rJhfy/nza5lfV4GZ+ipECokV2ng5K1as8HXr1sVdhoQ6erI8s7OVdTsOs37HYZ78j8O0dwdHOc2aUcLyeUFAnD+/lnMbM5SlkzFXLDI9mdl6d19xvHbaUpATUlma4sIzZnHhGUF/RS7nvLDvKOvDkFi/4xA/37x3sH1FSZLK0hSVJUkqSlLMKE1RUZqksiT1yrLSYFnl4P1gWVVZmrm15dRXlWoLRCQiCgU5qRIJ4+xTqjj7lCree8E8AA4c7eHJHYfZvOcIR7uzdPRm6ejpp7M3y9GeLIc6etl5qJPO3n6O9mTp7O0f9bKjZelEeEhtJfPrKphfF/SPzJ9ZQVNtBSUpdYCLTJRCQSI3a0Ypbz7nFN58ziljau/u9GRzdPb209HzSoi0dfXScriLHQeDTvCdhzp5dNt+uvteGeMpYTAnU868mXlhUVfB/JmVnFpThgN9/Tn6sk5vf45sLm+6P0dfvwfLh5nO5nLkco4DOWdwqHJ3yHkw3x0cD249vCVYnjCjuixFTUUJmYo0tRUl1JQHt1VlKRIn6VyRXM5p78lypKuPtq6+wdvO3n5mVZVyaqaMU2vKqdShxjIMfSpkyjEzytJJytJJZlaWjNrW3dnf3hMcWnswOLx256FOdhzsYM2WvRw4WhhDiScMMuVpaipKqKlIU/Oq6RJqK9PMKE3R0dt/zJd9W1cfR7rD6c4+2nuyjKWrMFOeZk6mjMaacubUBEHRWFPOnEw5p9aU0VBdRlqHHY+Lu9Ofc7I5f+Wfif4cvf05+nNOVVnwuz1Z/wBEQaEgBc3MmF1dxuzqMlYsmHnM8o6e7GBgvNzWRTJhpJMJ0skEqaRRMnQ6lSAVtikZMp1MGAkzEgaGgQVHXSXMMIJpw4LbvOmB5Tl3jnRnae3s5XBnH21dvRzu6KO1q4/Wzl5aO/s43NlLW1cfB4728sK+o4Nf8kOVphJkytNUl6fJlKeZXVXGGfUzXjWvujxNdVkwnSlPU16S5MDRHna3drG7tTu87QqOKNtx+JjzUxIGs6vKOLWmjDk15ZxSXYZ7sKXVmw22oHqHTPdlnZ7+HH3Z8P6rpp3SVIKKkiDwK8J+pVemk8NMpwany0uSDP0uHSn8hpvt7vRmc3Rnc/T09dOTzdEd3g7cf9W8bD/dfcFtT1+O7mw/fVmnLxe8r2y/D25NDm5l5nLHDeSEQW1FCTMrg5+6GSXUVpRQF96fOaN0cLqusoTaypJJDWcdfSQyxfX152jr6qO9O0tlaZLqsnQkR3F19GTZ09bFrtZu9uQFxu7WLva0dbP3SDcJM0pSCdLJgdsEJWFoDkynUwPzXgnddCpBOmGDuwW7+vrp6g36lbr6cnT1Zl81PztKn1JUSlMJytJJSlMJStMJylJJStMJSlNJytKvvM9U+D5TCRt8X8E/FsF6yf8n45U2CRIJ40hXEPwHO3o5dLSXQx29HOzo4VBHL61dfSMGSnVZiroZpfyXy87iqvNOndD709FHIkUinUwwa0Yps2aURvo6laUpzphdxRmzqyJ9nbHozeaGBEc/3X39w35pjnwg2rELgi/+4It+6Bd+3Ee0ZftztHb1BUERBsahjh4OdfRxqKOHgx291FZEf4KoQkFEppySVPBf+XQ6Sz6VH/4N8dWhXiQRERmkUBARkUGRhoKZXW5mz5vZNjO7dZjlpWb2/XD542a2IMp6RERkdJGFgpklgduAK4DFwPVmtnhIsw8Dh939DOAfgC9EVY+IiBxflFsKK4Ft7r7d3XuB7wFXD2lzNfDtcPqHwJss7kMARESmsShDoRHYmXe/JZw3bBt3zwJtQN3QJzKzm8xsnZmt279/f0TliohIQXQ0u/vt7r7C3VfU19fHXY6ISNGKMhR2AXPz7jeF84ZtY2YpIAMcjLAmEREZRZQnrz0BnGlmCwm+/K8D3jukzQPAB4DHgHcBv/LjjLuxfv36A2a2Y4I1zQIOTPCxk0H1nRjVd+Kmeo2qb+Lmj6VRZKHg7lkzuxl4CEgCd7r7JjP7PLDO3R8AvgncZWbbgEMEwXG8553w/iMzWzeWsT/iovpOjOo7cVO9RtUXvUiHuXD31cDqIfM+mzfdDbw7yhpERGTsCqKjWUREJsd0C4Xb4y7gOFTfiVF9J26q16j6IlZw11MQEZHoTLctBRHmdJfDAAAGBklEQVQRGYVCQUREBhVlKEzl0VnNbK6Z/drMNpvZJjO7ZZg2l5pZm5k9Hf58drjnirDGl8zs2fC1j7n2qQW+HK6/DWa2fBJrOztvvTxtZkfM7OND2kz6+jOzO81sn5ltzJs308x+YWYvhLe1Izz2A2GbF8zsA5NU2xfN7Lnw93e/mdWM8NhRPwsR1/g5M9uV93u8coTHjvr3HmF938+r7SUze3qEx07KOjxp3L2ofgjOiXgROA0oAZ4BFg9p88fA18Pp64DvT2J9c4Dl4XQVsHWY+i4FfhrjOnwJmDXK8iuBBwmud/g64PEYf9cvA/PjXn/AG4DlwMa8eX8L3BpO3wp8YZjHzQS2h7e14XTtJNT2ZiAVTn9huNrG8lmIuMbPAX8xhs/AqH/vUdU3ZPn/BT4b5zo8WT/FuKUwpUdndfc97v5kON0ObOHYgQKnuquB73hgLVBjZnNiqONNwIvuPtEz3E8ad/83ghMw8+V/zr4NvH2Yh/4h8At3P+Tuh4FfAJdHXZu7/9yDQSgB1hIMQxObEdbfWIzl7/2EjVZf+N1xLXD3yX7dOBRjKJy00VmjFu62WgY8Pszi15vZM2b2oJmdM6mFgQM/N7P1ZnbTMMvHso4nw3WM/IcY5/ob0ODue8Lplxn+yrtTYV1+iGDLbzjH+yxE7eZwF9edI+x+mwrr7xJgr7u/MMLyuNfhuBRjKBQEM5sB3At83N2PDFn8JMEukfOArwA/muTyLnb35QQXSPoTM3vDJL/+cZlZCXAV8INhFse9/o7hwX6EKXf8t5l9GsgC3x2hSZyfhX8CTgeWAnsIdtFMRdcz+lbClP97yleMoTDlR2c1szRBIHzX3e8butzdj7j70XB6NZA2s1mTVZ+77wpv9wH3E2yi5xvLOo7aFcCT7r536IK411+evQO71cLbfcO0iW1dmtmNwFuB94WhdYwxfBYi4+573b3f3XPAHSO8dqyfxfD74xrg+yO1iXMdTkQxhsLg6Kzhf5PXEYzGmm9gdFYY4+isJ0u4//GbwBZ3//sR2pwy0MdhZisJfk+TElpmVmlmVQPTBB2SG4c0ewD4T+FRSK8D2vJ2k0yWEf87i3P9DZH/OfsA8ONh2jwEvNnMasPdI28O50XKzC4H/itwlbt3jtBmLJ+FKGvM76d6xwivPZa/9yitAp5z95bhFsa9Dick7p7uKH4Ijo7ZSnBUwqfDeZ8n+AMAKCPY7bAN+B1w2iTWdjHBboQNwNPhz5XAx4CPhW1uBjYRHEmxFrhwEus7LXzdZ8IaBtZffn1GcP3tF4FngRWT/PutJPiSz+TNi3X9EQTUHqCPYL/2hwn6qX4JvACsAWaGbVcA/5z32A+Fn8VtwAcnqbZtBPviBz6DA0fjnQqsHu2zMInr767w87WB4It+ztAaw/vH/L1PRn3h/G8NfO7y2sayDk/Wj4a5EBGRQcW4+0hERCZIoSAiIoMUCiIiMkihICIigxQKIiIySKEgMonCEVx/GncdIiNRKIiIyCCFgsgwzOwGM/tdOAb+N8wsaWZHzewfLLgOxi/NrD5su9TM1uZdm6A2nH+Gma0JB+Z70sxOD59+hpn9MLyewXcna4RekbFQKIgMYWaLgPcAF7n7UqAfeB/BmdTr3P0c4BHgr8OHfAf4S3dvJjgDd2D+d4HbPBiY70KCM2IhGBn348BigjNeL4r8TYmMUSruAkSmoDcB5wNPhP/ElxMMZpfjlYHP/gW4z8wyQI27PxLO/zbwg3C8m0Z3vx/A3bsBwuf7nYdj5YRX61oAPBr92xI5PoWCyLEM+La7f+pVM83+aki7iY4R05M33Y/+DmUK0e4jkWP9EniXmc2GwWstzyf4e3lX2Oa9wKPu3gYcNrNLwvnvBx7x4Kp6LWb29vA5Ss2sYlLfhcgE6D8UkSHcfbOZfYbgalkJgpEx/wToAFaGy/YR9DtAMCz218Mv/e3AB8P57we+YWafD5/j3ZP4NkQmRKOkioyRmR119xlx1yESJe0+EhGRQdpSEBGRQdpSEBGRQQoFEREZpFAQEZFBCgURERmkUBARkUH/H2FsQXNj93AqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This tutorial is divided into the following parts:\n",
    "# 1. Word Embeddings + CNN = Text Classi\f",
    "cation\n",
    "# 2. Use a Single Layer CNN Architecture\n",
    "# 3. Dial in CNN Hyperparameters\n",
    "# 4. Consider Character-Level CNNs\n",
    "# 5. Consider Deeper CNNs for Classi\f",
    "cation\n",
    "\n",
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 300)(inputs1)\n",
    "#     embedding1 = Embedding(vocab_size,  300, weights=[embedding_matrix], trainable=False)(inputs1)\n",
    "#         model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length , trainable=False))\n",
    "\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 300)(inputs2)\n",
    "#     embedding2 = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 300)(inputs3)\n",
    "#     embedding3 = Embedding(vocab_size, 100)(embedding3)\n",
    "#     embedding3 = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(inputs3)\n",
    "\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    \n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(3, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = encode_text(tokenizer, xtrain_docs, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 103)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 103, 300)     922500      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 103, 300)     922500      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 103, 300)     922500      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 100, 32)      38432       embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 98, 32)       57632       embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 96, 32)       76832       embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100, 32)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 98, 32)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 96, 32)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 50, 32)       0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 49, 32)       0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 48, 32)       0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 1600)         0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 1568)         0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 1536)         0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4704)         0           flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_187 (Dense)               (None, 10)           47050       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_188 (Dense)               (None, 3)            33          dense_187[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,987,479\n",
      "Trainable params: 2,987,479\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 8s 7ms/step - loss: 1.0559 - acc: 0.4636\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.7890 - acc: 0.6221\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.4387 - acc: 0.8199\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.2152 - acc: 0.9400\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.1192 - acc: 0.9608\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0908 - acc: 0.9696\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0719 - acc: 0.9720\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0747 - acc: 0.9720\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9752\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0528 - acc: 0.9744\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0519 - acc: 0.9736\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0488 - acc: 0.9728\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0471 - acc: 0.9752\n",
      "Epoch 14/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0426 - acc: 0.9744\n",
      "Epoch 15/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0398 - acc: 0.9768\n",
      "Epoch 16/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0412 - acc: 0.9760\n",
      "Epoch 17/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0394 - acc: 0.9752\n",
      "Epoch 18/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0382 - acc: 0.9800\n",
      "Epoch 19/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0399 - acc: 0.9744\n",
      "Epoch 20/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0431 - acc: 0.9736\n",
      "Epoch 21/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0540 - acc: 0.9704\n",
      "Epoch 22/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0421 - acc: 0.9736\n",
      "Epoch 23/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0408 - acc: 0.9768\n",
      "Epoch 24/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0386 - acc: 0.9792\n",
      "Epoch 25/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0388 - acc: 0.9776\n",
      "Epoch 26/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0394 - acc: 0.9760\n",
      "Epoch 27/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0366 - acc: 0.9760\n",
      "Epoch 28/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0361 - acc: 0.9784\n",
      "Epoch 29/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0345 - acc: 0.9768\n",
      "Epoch 30/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0338 - acc: 0.9784\n",
      "Epoch 31/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0353 - acc: 0.9768\n",
      "Epoch 32/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0350 - acc: 0.9776\n",
      "Epoch 33/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0349 - acc: 0.9768\n",
      "Epoch 34/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0351 - acc: 0.9776\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0381 - acc: 0.9768\n",
      "Epoch 36/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0353 - acc: 0.9744\n",
      "Epoch 37/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0345 - acc: 0.9760\n",
      "Epoch 38/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0374 - acc: 0.9760\n",
      "Epoch 39/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0350 - acc: 0.9760\n",
      "Epoch 40/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0341 - acc: 0.9776\n",
      "Epoch 41/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0339 - acc: 0.9824\n",
      "Epoch 42/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0345 - acc: 0.9768\n",
      "Epoch 43/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0334 - acc: 0.9816\n",
      "Epoch 44/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9784\n",
      "Epoch 45/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0343 - acc: 0.9768\n",
      "Epoch 46/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0347 - acc: 0.9784\n",
      "Epoch 47/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0325 - acc: 0.9776\n",
      "Epoch 48/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0337 - acc: 0.9768\n",
      "Epoch 49/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0317 - acc: 0.9800\n",
      "Epoch 50/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0339 - acc: 0.9784\n",
      "Epoch 51/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0321 - acc: 0.9784\n",
      "Epoch 52/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0344 - acc: 0.9768\n",
      "Epoch 53/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0325 - acc: 0.9776\n",
      "Epoch 54/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0332 - acc: 0.9776\n",
      "Epoch 55/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0346 - acc: 0.9792\n",
      "Epoch 56/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0327 - acc: 0.9776\n",
      "Epoch 57/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0339 - acc: 0.9784\n",
      "Epoch 58/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0327 - acc: 0.9792\n",
      "Epoch 59/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0327 - acc: 0.9768\n",
      "Epoch 60/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0350 - acc: 0.9752\n",
      "Epoch 61/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0333 - acc: 0.9744\n",
      "Epoch 62/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0333 - acc: 0.9752\n",
      "Epoch 63/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0334 - acc: 0.9776\n",
      "Epoch 64/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9768\n",
      "Epoch 65/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0326 - acc: 0.9784\n",
      "Epoch 66/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0328 - acc: 0.9768\n",
      "Epoch 67/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0332 - acc: 0.9784\n",
      "Epoch 68/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0335 - acc: 0.9752\n",
      "Epoch 69/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0328 - acc: 0.9808\n",
      "Epoch 70/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0326 - acc: 0.9800\n",
      "Epoch 71/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0326 - acc: 0.9792\n",
      "Epoch 72/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0324 - acc: 0.9776\n",
      "Epoch 73/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0335 - acc: 0.9792\n",
      "Epoch 74/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.1268 - acc: 0.9512\n",
      "Epoch 75/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0940 - acc: 0.9672\n",
      "Epoch 76/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0516 - acc: 0.9720\n",
      "Epoch 77/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0379 - acc: 0.9808\n",
      "Epoch 78/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0369 - acc: 0.9792\n",
      "Epoch 79/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0351 - acc: 0.9768\n",
      "Epoch 80/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0348 - acc: 0.9784\n",
      "Epoch 81/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0339 - acc: 0.9776\n",
      "Epoch 82/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9776\n",
      "Epoch 83/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9776\n",
      "Epoch 84/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0343 - acc: 0.9752\n",
      "Epoch 85/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0334 - acc: 0.9776\n",
      "Epoch 86/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9776\n",
      "Epoch 87/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0342 - acc: 0.9800\n",
      "Epoch 88/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0325 - acc: 0.9784\n",
      "Epoch 89/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0325 - acc: 0.9792\n",
      "Epoch 90/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0324 - acc: 0.9768\n",
      "Epoch 91/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0338 - acc: 0.9784\n",
      "Epoch 92/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0326 - acc: 0.9776\n",
      "Epoch 93/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0338 - acc: 0.9784\n",
      "Epoch 94/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0334 - acc: 0.9768\n",
      "Epoch 95/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0332 - acc: 0.9776\n",
      "Epoch 96/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0340 - acc: 0.9752\n",
      "Epoch 97/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0332 - acc: 0.9800\n",
      "Epoch 98/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0328 - acc: 0.9792\n",
      "Epoch 99/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0330 - acc: 0.9800\n",
      "Epoch 100/100\n",
      "1249/1249 [==============================] - 3s 2ms/step - loss: 0.0344 - acc: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb62fb4afd0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = encode_text(tokenizer, xtrain_docs, max_length)\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "# fit model\n",
    "model.fit([trainX,trainX,trainX], array(trainLabels), epochs=100, batch_size=16 , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--. 1 root root 35354088 May 31 16:26 /home/surya/model_multi_nightingale.h5\r\n"
     ]
    }
   ],
   "source": [
    "! ls -ltr /home/surya/model_multi_nightingale.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model_path = tf.contrib.saved_model.save_keras_model(model, \"./saved_models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.keras.backend.get_session() as sess:\n",
    "    tf.saved_model.simple_save(\n",
    "        sess,\n",
    "        \"export_path\",\n",
    "        inputs={'input': keras_model.input},\n",
    "        outputs={'output': keras_model.output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.experimental.export_saved_model(model, '/home/surya/saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to a SavedModel\n",
    "keras.experimental.export_saved_model(model, 'path_to_saved_model')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = keras.experimental.load_from_saved_model('path_to_saved_model')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.keras.log_model(model, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "mlflow.keras.save_model(model, \"models_keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import mlflow\n",
    ">>> # Build, compile, and train your model\n",
    ">>> keras_model = ...\n",
    ">>> keras_model_path = ...\n",
    ">>> keras_model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    ">>> results = keras_model.fit(\n",
    "...     x_train, y_train, epochs=20, batch_size = 128, validation_data=(x_val, y_val))\n",
    "... # Save the model as an MLflow Model\n",
    ">>> mlflow.keras.save_model(keras_model, keras_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
